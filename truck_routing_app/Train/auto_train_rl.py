#!/usr/bin/env python
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         AUTO TRAIN RL - MASTER                        â•‘
â•‘                                                                       â•‘
â•‘        CÃ´ng cá»¥ tá»± Ä‘á»™ng huáº¥n luyá»‡n RL agent cho Ä‘á»‹nh tuyáº¿n xe táº£i     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CÃ´ng cá»¥ nÃ y tá»± Ä‘á»™ng hÃ³a toÃ n bá»™ quÃ¡ trÃ¬nh huáº¥n luyá»‡n:
1. Tá»± Ä‘á»™ng táº¡o báº£n Ä‘á»“ train vÃ  test theo kÃ­ch thÆ°á»›c yÃªu cáº§u
2. Tá»± Ä‘á»™ng cáº¥u hÃ¬nh mÃ´i trÆ°á»ng vÃ  tham sá»‘ phÃ¹ há»£p vá»›i kÃ­ch thÆ°á»›c báº£n Ä‘á»“
3. Huáº¥n luyá»‡n agent vá»›i siÃªu tham sá»‘ tá»‘i Æ°u cho tá»«ng kÃ­ch thÆ°á»›c báº£n Ä‘á»“
4. ÄÃ¡nh giÃ¡ chi tiáº¿t vÃ  lÆ°u káº¿t quáº£

CÃ¡ch sá»­ dá»¥ng: 
python auto_train_rl.py

hoáº·c vá»›i tham sá»‘ chá»‰ Ä‘á»‹nh:
python auto_train_rl.py --map-size 8 --num-maps 20 --training-steps 100000 --advanced

CÃ¡c tÃ¹y chá»n:
--map-size: KÃ­ch thÆ°á»›c báº£n Ä‘á»“ (máº·c Ä‘á»‹nh: 8, há»— trá»£: 8, 9, 10, 12, 15)
--num-maps: Sá»‘ lÆ°á»£ng báº£n Ä‘á»“ táº¡o cho má»—i loáº¡i
--training-steps: Sá»‘ bÆ°á»›c huáº¥n luyá»‡n
--advanced: Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nÃ¢ng cao (Double DQN, Dueling, PER)
--render: Hiá»ƒn thá»‹ quÃ¡ trÃ¬nh huáº¥n luyá»‡n
"""

import os
import sys
import time
import json
import random
import argparse
import numpy as np
from datetime import datetime
from pathlib import Path
import uuid
import shutil
import rich
import re
import traceback # THÃŠM IMPORT NÃ€Y

# ThÃªm thÆ° viá»‡n UI cho terminal
try:
    from rich.console import Console
    from rich.panel import Panel
    from rich.table import Table
    from rich.progress import Progress, TextColumn, BarColumn, TaskProgressColumn, TimeRemainingColumn, SpinnerColumn
    from rich.prompt import Prompt, Confirm
    from rich.markdown import Markdown
    from rich.style import Style
    from rich.text import Text
    from rich.layout import Layout
    from rich.live import Live
    from rich import box
    from rich.align import Align
    from tqdm import tqdm
    
    RICH_AVAILABLE = True
except ImportError:
    print("ThÆ° viá»‡n Rich khÃ´ng kháº£ dá»¥ng. Äang cÃ i Ä‘áº·t...")
    import subprocess
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "rich", "tqdm"])
        from rich.console import Console
        from rich.panel import Panel
        from rich.table import Table
        from rich.progress import Progress, TextColumn, BarColumn, TaskProgressColumn, TimeRemainingColumn, SpinnerColumn
        from rich.prompt import Prompt, Confirm
        from rich.markdown import Markdown
        from rich.style import Style
        from rich.text import Text
        from rich.layout import Layout
        from rich.live import Live
        from rich import box
        from rich.align import Align
        from tqdm import tqdm
        
        RICH_AVAILABLE = True
    except:
        print("KhÃ´ng thá»ƒ cÃ i Ä‘áº·t Rich. Sá»­ dá»¥ng giao diá»‡n cÆ¡ báº£n.")
        RICH_AVAILABLE = False

# Khá»Ÿi táº¡o console
if RICH_AVAILABLE:
    console = Console()
else:
    class SimpleConsole:
        def print(self, *args, **kwargs):
            print(*args)
        def rule(self, title):
            print("\n" + "=" * 80)
            print(title.center(80))
            print("=" * 80)
    console = SimpleConsole()

# Äáº£m báº£o thÆ° má»¥c hiá»‡n táº¡i Ä‘Æ°á»£c thÃªm vÃ o path
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

# Táº¡o ID phiÃªn duy nháº¥t
SESSION_ID = datetime.now().strftime("%Y%m%d_%H%M%S") + "_" + str(uuid.uuid4())[:8]

# Import cÃ¡c module cáº§n thiáº¿t
try:
    from core.map import Map
    from core.constants import CellType, MovementCosts, StationCosts
    from core.rl_environment import TruckRoutingEnv
    from core.rl_environment import (
        DEFAULT_MAX_FUEL_RANGE, DEFAULT_INITIAL_FUEL_RANGE, 
        DEFAULT_INITIAL_MONEY_RANGE, DEFAULT_FUEL_PER_MOVE_RANGE,
        DEFAULT_GAS_STATION_COST_RANGE, DEFAULT_TOLL_BASE_COST_RANGE
    )
    from core.algorithms.rl_DQNAgent import DQNAgentTrainer
    from core.algorithms.greedy import GreedySearch
    from truck_routing_app.statistics.rl_evaluation import RLEvaluator
    from stable_baselines3.common.callbacks import BaseCallback # <--- IMPORT THÃŠM
except ImportError as e:
    if RICH_AVAILABLE:
        console.print(f"[bold red]Lá»—i khi import module:[/] {e}")
    else:
        print(f"Lá»—i khi import module: {e}")
    sys.exit(1)

# CÃ¡c siÃªu tham sá»‘ tá»‘i Æ°u cho tá»«ng kÃ­ch thÆ°á»›c báº£n Ä‘á»“
# ÄÆ°á»£c xÃ¡c Ä‘á»‹nh trÆ°á»›c qua thá»­ nghiá»‡m
OPTIMAL_HYPERPARAMS = {
    8: {
        "learning_rate": 0.0003,
        "gamma": 0.99,
        "buffer_size": 50000,
        "learning_starts": 5000,
        "batch_size": 64,
        "tau": 0.005,
        "train_freq": 4,
        "target_update_interval": 5000,
        "exploration_fraction": 0.8,  # TÄƒng tá»« 0.6 lÃªn 0.8 Ä‘á»ƒ agent khÃ¡m phÃ¡ nhiá»u hÆ¡n
        "exploration_initial_eps": 1.0,
        "exploration_final_eps": 0.02,  # Giáº£m tá»« 0.05 xuá»‘ng 0.02 Ä‘á»ƒ cÃ³ khai thÃ¡c tá»‘t hÆ¡n cuá»‘i cÃ¹ng
        "policy_kwargs": {"net_arch": [256, 256]},  # TÄƒng tá»« 128,128 lÃªn 256,256
        "double_q": True,
        "dueling_net": True,
        "prioritized_replay": True,
        "prioritized_replay_alpha": 0.6,
        "prioritized_replay_beta0": 0.4
    },
    9: {
        "learning_rate": 0.00005,
        "gamma": 0.99,
        "buffer_size": 100000,
        "learning_starts": 2000,
        "batch_size": 64,
        "tau": 0.005,
        "train_freq": 4,
        "target_update_interval": 1000,
        "exploration_fraction": 0.4,
        "exploration_initial_eps": 1.0,
        "exploration_final_eps": 0.05,
        "policy_kwargs": {"net_arch": [128, 128]},
        "double_q": True,
        "dueling_net": True,
        "prioritized_replay": True,
        "prioritized_replay_alpha": 0.6,
        "prioritized_replay_beta0": 0.4
    },
    10: {
        "learning_rate": 0.00005,
        "gamma": 0.995,
        "buffer_size": 100000,
        "learning_starts": 2000,
        "batch_size": 128,
        "tau": 0.005,
        "train_freq": 4,
        "target_update_interval": 1000,
        "exploration_fraction": 0.4,
        "exploration_initial_eps": 1.0,
        "exploration_final_eps": 0.05,
        "policy_kwargs": {"net_arch": [256, 256]},
        "double_q": True,
        "dueling_net": True,
        "prioritized_replay": True,
        "prioritized_replay_alpha": 0.6,
        "prioritized_replay_beta0": 0.4
    },
    12: {
        "learning_rate": 0.00003,
        "gamma": 0.995,
        "buffer_size": 150000,
        "learning_starts": 5000,
        "batch_size": 128,
        "tau": 0.005,
        "train_freq": 4,
        "target_update_interval": 1000,
        "exploration_fraction": 0.4,
        "exploration_initial_eps": 1.0,
        "exploration_final_eps": 0.05,
        "policy_kwargs": {"net_arch": [256, 256]},
        "double_q": True,
        "dueling_net": True,
        "prioritized_replay": True,
        "prioritized_replay_alpha": 0.6,
        "prioritized_replay_beta0": 0.4
    },
    15: {
        "learning_rate": 0.00002,
        "gamma": 0.995,
        "buffer_size": 200000,
        "learning_starts": 10000,
        "batch_size": 256,
        "tau": 0.001,
        "train_freq": 4,
        "target_update_interval": 1000,
        "exploration_fraction": 0.4,
        "exploration_initial_eps": 1.0,
        "exploration_final_eps": 0.05,
        "policy_kwargs": {"net_arch": [512, 256]},
        "double_q": True,
        "dueling_net": True,
        "prioritized_replay": True,
        "prioritized_replay_alpha": 0.6,
        "prioritized_replay_beta0": 0.4
    }
}

# Tham sá»‘ mÃ´i trÆ°á»ng tá»‘i Æ°u cho tá»«ng kÃ­ch thÆ°á»›c báº£n Ä‘á»“
OPTIMAL_ENV_PARAMS = {
    8: {
        "initial_fuel": 50.0,
        "initial_money": 1000.0,
        "fuel_per_move": 0.5,
        "gas_station_cost": 10,
        "toll_base_cost": 5,
        "max_steps": 200
    },
    9: {
        "initial_fuel": 50.0,
        "initial_money": 1500.0,
        "fuel_per_move": 0.5,
        "gas_station_cost": 10,
        "toll_base_cost": 5,
        "max_steps": 250
    },
    10: {
        "initial_fuel": 50.0,
        "initial_money": 1500.0,
        "fuel_per_move": 0.5,
        "gas_station_cost": 10,
        "toll_base_cost": 5,
        "max_steps": 300
    },
    12: {
        "initial_fuel": 50.0,
        "initial_money": 1500.0,
        "fuel_per_move": 0.5,
        "gas_station_cost": 10,
        "toll_base_cost": 5,
        "max_steps": 350
    },
    15: {
        "initial_fuel": 50.0,
        "initial_money": 1500.0,
        "fuel_per_move": 0.5,
        "gas_station_cost": 10,
        "toll_base_cost": 5,
        "max_steps": 500
    }
}

# Tá»· lá»‡ tá»‘i Æ°u cho cÃ¡c loáº¡i Ã´ Ä‘áº·c biá»‡t theo kÃ­ch thÆ°á»›c báº£n Ä‘á»“
OPTIMAL_MAP_RATIOS = {
    8: {"toll_ratio": 0.03, "gas_ratio": 0.07, "brick_ratio": 0.12},
    9: {"toll_ratio": 0.03, "gas_ratio": 0.07, "brick_ratio": 0.12},
    10: {"toll_ratio": 0.03, "gas_ratio": 0.07, "brick_ratio": 0.12},
    12: {"toll_ratio": 0.025, "gas_ratio": 0.07, "brick_ratio": 0.12},
    15: {"toll_ratio": 0.02, "gas_ratio": 0.07, "brick_ratio": 0.12}
}

# MÃ u sáº¯c vÃ  biá»ƒu tÆ°á»£ng
COLORS = {
    "info": "cyan",
    "success": "green",
    "warning": "yellow",
    "error": "red",
    "highlight": "magenta",
    "title": "bright_blue",
    "step": "bright_green",
    "training": "blue",
    "header": "#00ff00",  # Bright green for main header (hacker style)
    "subheader": "#1fa8b7",  # Cyan-ish for subheaders
    "border": "#00ffff",  # Cyan border
    "menu_number": "#ff00ff",  # Magenta for menu numbers
    "menu_text": "#ffffff",  # White for menu text
    "accent": "#ff0000",  # Red for accent
    "progress": "#00ff00",  # Green for progress bars
    "prompt": "#ffff00",  # Yellow for prompts
    "tech": "#0000ff"     # Blue for technical elements
}

ICONS = {
    "info": "â„¹ï¸",
    "success": "âœ…",
    "warning": "âš ï¸",
    "error": "âŒ",
    "map": "ğŸ—ºï¸",
    "training": "ğŸš€",
    "model": "ğŸ’¾",
    "evaluation": "ğŸ“Š",
    "time": "â±ï¸",
    "config": "âš™ï¸",
    "analytics": "ğŸ“ˆ",
    "folder": "ğŸ“",
    "map_size": "ğŸ“",
    "steps": "ğŸ‘£"
}

# Regex Ä‘á»ƒ tÃ¬m SESSION_ID trong tÃªn file, vÃ­ dá»¥: _20231027_153000_abcdef12_
# NÃ³ tÃ¬m má»™t chuá»—i báº¯t Ä‘áº§u báº±ng gáº¡ch dÆ°á»›i, theo sau lÃ  8 chá»¯ sá»‘ (YYYYMMDD),
# gáº¡ch dÆ°á»›i, 6 chá»¯ sá»‘ (HHMMSS), gáº¡ch dÆ°á»›i, vÃ  8 kÃ½ tá»± hex.
SESSION_ID_PATTERN_IN_FILENAME_RE = re.compile(r"(\d{8})_(\d{6})_([a-f0-9]{8})")

# Cáº¥u trÃºc thÆ° má»¥c
DIRECTORIES = {
    "maps": { # Note: MAPS_DIR will be _ROOT_DIR / "maps" due to this being a dict
        "train": "maps/train",
        "eval": "maps/eval",
        "test": "maps/test",
    },
    "models": "saved_models",
    "logs": "training_logs",
    "results": "evaluation_results",
    "sessions": "sessions" # Ensure this key exists
}

# Define global Path constants immediately after DIRECTORIES
_ROOT_DIR = Path(__file__).resolve().parent

# DIRECTORIES["maps"] is a dict, so MAPS_DIR needs to point to the general 'maps' folder directly.
MAPS_DIR = _ROOT_DIR / "maps" 
MODELS_DIR = _ROOT_DIR / DIRECTORIES["models"]
LOGS_DIR = _ROOT_DIR / DIRECTORIES["logs"]
RESULTS_DIR = _ROOT_DIR / DIRECTORIES["results"]
SESSIONS_DIR = _ROOT_DIR / DIRECTORIES["sessions"]

# Create these base directories if they don't exist to be safe, though specific session/type dirs are created later.
MAPS_DIR.mkdir(parents=True, exist_ok=True)
MODELS_DIR.mkdir(parents=True, exist_ok=True)
LOGS_DIR.mkdir(parents=True, exist_ok=True)
RESULTS_DIR.mkdir(parents=True, exist_ok=True)
SESSIONS_DIR.mkdir(parents=True, exist_ok=True)

# Máº«u tÃªn file
FILE_TEMPLATES = {
    "map": "map_{size}x{size}_{index}_{timestamp}.json",
    "model": "rl_agent_size_{size}{variant}_{steps}_{session_id}.zip",
    "results": "results_{size}x{size}_success{success_rate:.0f}_{session_id}.json"
}

# Logo vÃ  banner
RL_TOOL_LOGO = """
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—     
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
   â•šâ•â•   â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â•â•šâ•â•  â•šâ•â•    â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•
                                                               
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
 â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
 â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
 â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘
 â•šâ•â•  â•šâ•â•â•šâ•â•    â•šâ•â•     â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•   â•šâ•â•   â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•
                                                           v2.0
"""

MENU_SEPARATOR = "â•" * 70  # Using solid unicode separator for a more technical look

def display_header():
    """Hiá»ƒn thá»‹ header cá»§a á»©ng dá»¥ng"""
    if RICH_AVAILABLE:
        # Header vá»›i logo
        console.print()
        header_panel = Panel(
            Align.center(Text(RL_TOOL_LOGO, style=f"bold {COLORS['header']}")),
            border_style=COLORS["border"],
            box=box.DOUBLE,
            width=90,
            padding=(0, 2)
        )
        console.print(header_panel)
        
        # Subtitle
        subtitle = Text("[ ADVANCED REINFORCEMENT LEARNING TRAINING FRAMEWORK ]", style=f"bold {COLORS['subheader']}")
        console.print(Align.center(subtitle))
        
        # Separator
        console.print(Align.center(Text(MENU_SEPARATOR, style=COLORS["border"])))
    else:
        print("\n" + "=" * 80)
        print("TRUCK RL AGENT - CÃ´ng cá»¥ huáº¥n luyá»‡n tá»± Ä‘á»™ng".center(80))
        print("=" * 80)

def display_menu():
    """Hiá»ƒn thá»‹ menu chá»©c nÄƒng"""
    if RICH_AVAILABLE:
        menu_table = Table(show_header=False, box=None, padding=(0, 2))
        menu_table.add_column("Option", style=COLORS["menu_number"], justify="right", width=6)
        menu_table.add_column("Description", style=COLORS["menu_text"])
        
        menu_table.add_row("[1]", "QUICK TRAIN (Huáº¥n luyá»‡n nhanh - 8x8, cáº¥u hÃ¬nh máº·c Ä‘á»‹nh)")
        menu_table.add_row("[2]", "MASTER MODE (Chá»‰ cáº§n nháº­p kÃ­ch thÆ°á»›c báº£n Ä‘á»“, tá»± Ä‘á»™ng tá»‘i Æ°u hÃ³a)")
        menu_table.add_row("[3]", "ADVANCED TRAIN (Double DQN, Dueling, PER)")
        menu_table.add_row("[4]", "EVALUATE MODEL (ÄÃ¡nh giÃ¡ model Ä‘Ã£ huáº¥n luyá»‡n)")
        menu_table.add_row("[5]", "GENERATE MAPS (Táº¡o bá»™ báº£n Ä‘á»“ má»›i)")
        menu_table.add_row("[6]", "HELP MANUAL (ThÃ´ng tin trá»£ giÃºp)")
        menu_table.add_row("[0]", "EXIT (ThoÃ¡t)")
        
        menu_panel = Panel(
            menu_table,
            title="[ MAIN MENU ]",
            title_align="center",
            border_style=COLORS["border"],
            box=box.HEAVY,
            padding=(1, 2)
        )
        console.print(menu_panel)
        
        # Technical info display
        tech_info = Table(show_header=False, box=None, padding=(0, 1))
        tech_info.add_column("Label", style=COLORS["accent"], width=15)
        tech_info.add_column("Value", style="white")
        
        tech_info.add_row("Session ID:", SESSION_ID)
        tech_info.add_row("System:", f"Python {sys.version.split()[0]}")
        tech_info.add_row("Time:", datetime.now().strftime("%H:%M:%S %d/%m/%Y"))
        
        tech_panel = Panel(
            tech_info,
            title="[ SYSTEM INFO ]",
            title_align="center",
            border_style=COLORS["border"],
            box=box.SIMPLE,
            width=60
        )
        console.print(Align.center(tech_panel))
        
        # Footer
        console.print(Align.center(Text(MENU_SEPARATOR, style=COLORS["border"])))
        footer = Text("Coded by NHOM AI Â© 2023 | https://github.com/AI-NHOM", style=COLORS["accent"])
        console.print(Align.center(footer))
        console.print()
    else:
        print("\nMenu chá»©c nÄƒng:")
        print("  [1] QUICK TRAIN (Huáº¥n luyá»‡n nhanh - 8x8, cáº¥u hÃ¬nh máº·c Ä‘á»‹nh)")
        print("  [2] MASTER MODE (Chá»‰ cáº§n nháº­p kÃ­ch thÆ°á»›c báº£n Ä‘á»“, tá»± Ä‘á»™ng tá»‘i Æ°u hÃ³a)")
        print("  [3] ADVANCED TRAIN (Double DQN, Dueling, PER)")
        print("  [4] EVALUATE MODEL (ÄÃ¡nh giÃ¡ model Ä‘Ã£ huáº¥n luyá»‡n)")
        print("  [5] GENERATE MAPS (Táº¡o bá»™ báº£n Ä‘á»“ má»›i)")
        print("  [6] HELP MANUAL (ThÃ´ng tin trá»£ giÃºp)")
        print("  [0] EXIT (ThoÃ¡t)")
        print(f"\nSession ID: {SESSION_ID}")
        print(f"Thá»i gian: {datetime.now().strftime('%H:%M:%S %d/%m/%Y')}")

def get_user_choice():
    """Láº¥y lá»±a chá»n tá»« ngÆ°á»i dÃ¹ng"""
    if RICH_AVAILABLE:
        choice = Prompt.ask(
            "\n[bold cyan]Nháº­p lá»±a chá»n cá»§a báº¡n[/bold cyan]",
            choices=["0", "1", "2", "3", "4", "5", "6"],
            default="1"
        )
    else:
        choice = input("\nNháº­p lá»±a chá»n cá»§a báº¡n [1-6, 0 Ä‘á»ƒ thoÃ¡t]: ")
    return choice

def display_training_config(map_size, num_maps, training_steps, use_advanced):
    """Hiá»ƒn thá»‹ cáº¥u hÃ¬nh huáº¥n luyá»‡n hiá»‡n táº¡i"""
    if RICH_AVAILABLE:
        config_table = Table(show_header=True, box=box.SIMPLE)
        config_table.add_column("Tham sá»‘", style="cyan")
        config_table.add_column("GiÃ¡ trá»‹", style="green")
        
        config_table.add_row("KÃ­ch thÆ°á»›c báº£n Ä‘á»“", f"{map_size}x{map_size}")
        config_table.add_row("Sá»‘ lÆ°á»£ng báº£n Ä‘á»“", str(num_maps))
        config_table.add_row("Sá»‘ bÆ°á»›c huáº¥n luyá»‡n", f"{training_steps:,}")
        config_table.add_row("Sá»­ dá»¥ng ká»¹ thuáº­t nÃ¢ng cao", "âœ… CÃ³" if use_advanced else "âŒ KhÃ´ng")
        
        config_panel = Panel(
            config_table,
            title="[bold]Cáº¥u hÃ¬nh huáº¥n luyá»‡n[/bold]",
            title_align="center",
            border_style="blue",
            padding=(1, 2)
        )
        console.print(config_panel)
    else:
        print("\nCáº¥u hÃ¬nh huáº¥n luyá»‡n:")
        print(f"  KÃ­ch thÆ°á»›c báº£n Ä‘á»“: {map_size}x{map_size}")
        print(f"  Sá»‘ lÆ°á»£ng báº£n Ä‘á»“: {num_maps}")
        print(f"  Sá»‘ bÆ°á»›c huáº¥n luyá»‡n: {training_steps:,}")
        print(f"  Sá»­ dá»¥ng ká»¹ thuáº­t nÃ¢ng cao: {'CÃ³' if use_advanced else 'KhÃ´ng'}")

def clear_screen():
    """XÃ³a mÃ n hÃ¬nh terminal"""
    if sys.platform == "win32":
        os.system("cls")
    else:
        os.system("clear")

def setup_directories():
    """Táº¡o cÃ¡c thÆ° má»¥c cáº§n thiáº¿t náº¿u chÆ°a tá»“n táº¡i."""
    directories = [
        "maps/train",
        "maps/eval",
        "maps/test",
        "saved_models",
        "training_logs",
        "evaluation_results"
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
    
    if RICH_AVAILABLE:
        console.print("[bold green]âœ… ÄÃ£ táº¡o cÃ¡c thÆ° má»¥c cáº§n thiáº¿t[/bold green]")
    else:
        print("âœ… ÄÃ£ táº¡o cÃ¡c thÆ° má»¥c cáº§n thiáº¿t")
    return True

def generate_maps(base_log_dir, map_size, num_maps_per_set=10, map_ratios_override=None):
    """
    Generates a set of maps for a given size and saves them.
    Ensures each map has a path from start to end.
    Uses ratios from OPTIMAL_MAP_RATIOS unless overridden.
    """
    map_dir = base_log_dir / f"map_size_{map_size}" / "generated_maps"
    map_dir.mkdir(parents=True, exist_ok=True)
    print(f"Generating maps in: {map_dir}")

    generated_map_files = []

    if map_ratios_override:
        current_ratios = map_ratios_override
    else:
        # Láº¥y ratio tá»« OPTIMAL_MAP_RATIOS, náº¿u khÃ´ng cÃ³ cho size cá»¥ thá»ƒ, dÃ¹ng cá»§a size 10
        current_ratios = OPTIMAL_MAP_RATIOS.get(map_size, OPTIMAL_MAP_RATIOS.get(10))
        if not current_ratios:
            print(f"[Error] No OPTIMAL_MAP_RATIOS defined for map size {map_size} or fallback size 10.")
            return [] # Tráº£ vá» list rá»—ng náº¿u khÃ´ng cÃ³ ratio
            
    toll_ratio = current_ratios.get("toll_ratio", 0.05)
    gas_ratio = current_ratios.get("gas_ratio", 0.05)
    brick_ratio = current_ratios.get("brick_ratio", 0.2)

    print(f"Using ratios for map size {map_size}: Toll={toll_ratio:.3f}, Gas={gas_ratio:.3f}, Brick={brick_ratio:.3f}")

    maps_generated = 0
    attempts = 0
    max_total_attempts = num_maps_per_set * 20 # Giá»›i háº¡n tá»•ng sá»‘ láº§n thá»­ Ä‘á»ƒ trÃ¡nh káº¹t vÃ´ háº¡n

    while maps_generated < num_maps_per_set and attempts < max_total_attempts:
        attempts += 1

        # TÃ­nh toÃ¡n sá»‘ lÆ°á»£ng tá»« ratio (logic nÃ y cáº§n pháº£i cÃ³ vÃ¬ OPTIMAL_MAP_RATIOS dÃ¹ng ratio)
        total_cells = map_size * map_size
        effective_area = max(1, total_cells - 2) # Trá»« start/end Ä‘á»ƒ tÃ­nh toÃ¡n sá»‘ lÆ°á»£ng
        
        # ThÃªm random.uniform Ä‘á»ƒ cÃ³ sá»± biáº¿n thiÃªn nháº¹ vá» sá»‘ lÆ°á»£ng, tÆ°Æ¡ng tá»± nhÆ° cÃ¡ch cÃ¡c ratio nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu
        # lÃ  má»™t khoáº£ng giÃ¡ trá»‹ mong muá»‘n.
        num_tolls_calc = max(0, int(toll_ratio * effective_area * random.uniform(0.8, 1.2)))
        num_gas_calc = max(0, int(gas_ratio * effective_area * random.uniform(0.8, 1.2)))
        num_obstacles_calc = max(0, int(brick_ratio * effective_area * random.uniform(0.8, 1.2)))

        # Táº¡o báº£n Ä‘á»“ báº±ng cÃ¡ch gá»i phÆ°Æ¡ng thá»©c Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t cá»§a Map, truyá»n sá»‘ lÆ°á»£ng
        map_obj = Map.generate_random(
            size=map_size,
            num_tolls=num_tolls_calc,
            num_gas=num_gas_calc,
            num_obstacles=num_obstacles_calc
        )

        if map_obj:
            # ÄÃ£ cÃ³ kiá»ƒm tra has_path_from_start_to_end bÃªn trong generate_random
            map_filename = f"map_{map_size}x{map_size}_{maps_generated + 1}.json"
            full_map_path = map_dir / map_filename
            if map_obj.save(str(full_map_path)):
                generated_map_files.append(str(full_map_path))
                maps_generated += 1
                print(f"  Generated and saved: {map_filename} (Attempt {attempts})")
                stats = map_obj.get_statistics()
                print(f"    Actual counts: Tolls={stats['toll_stations']}, Gas={stats['gas_stations']}, Obstacles={stats['obstacles']}")
            else:
                print(f"  Failed to save map generated on attempt {attempts}.")
        else:
            # generate_random Ä‘Ã£ in warning náº¿u khÃ´ng táº¡o Ä‘Æ°á»£c map há»£p lá»‡
            print(f"  Map generation failed on attempt {attempts} for size {map_size}. Retrying...")
            time.sleep(0.1) # Chá» má»™t chÃºt trÆ°á»›c khi thá»­ láº¡i

    if maps_generated < num_maps_per_set:
        print(f"[Warning] Could only generate {maps_generated}/{num_maps_per_set} maps for size {map_size} after {max_total_attempts} attempts.")
    
    return generated_map_files

def create_environment(map_obj, map_size, render_mode=None):
    """Táº¡o mÃ´i trÆ°á»ng TruckRoutingEnv vá»›i cáº¥u hÃ¬nh tá»‘i Æ°u cho map_size."""
    # Láº¥y tham sá»‘ tá»‘i Æ°u cá»‘ Ä‘á»‹nh cho map_size nÃ y
    env_params_optimal = OPTIMAL_ENV_PARAMS.get(map_size, OPTIMAL_ENV_PARAMS[8]) 
    max_steps_for_env = env_params_optimal.get('max_steps', 2 * map_obj.size * map_obj.size)
    
    # Láº¥y cÃ¡c giÃ¡ trá»‹ max_fuel tá»« optimal hoáº·c default (cáº§n thiáº¿t cho TruckRoutingEnv init)
    # Sá»­ dá»¥ng initial_fuel lÃ m max_fuel náº¿u khÃ´ng cÃ³, hoáº·c giÃ¡ trá»‹ trung bÃ¬nh tá»« default range
    max_fuel_val = env_params_optimal.get('max_fuel', 
                                          env_params_optimal.get('initial_fuel', 
                                                                 (DEFAULT_MAX_FUEL_RANGE[0] + DEFAULT_MAX_FUEL_RANGE[1]) / 2))

    console.print(f"[info]Táº¡o mÃ´i trÆ°á»ng vá»›i Tham sá»‘ Tá»‘i Æ°u cho map_size {map_size}:[/info]")
    console.print(f"  Max Fuel: {max_fuel_val}") # Sá»­ dá»¥ng max_fuel_val Ä‘Ã£ xÃ¡c Ä‘á»‹nh
    console.print(f"  Initial Fuel: {env_params_optimal['initial_fuel']}")
    console.print(f"  Initial Money: {env_params_optimal['initial_money']}")
    console.print(f"  Fuel Per Move: {env_params_optimal['fuel_per_move']}")
    console.print(f"  Gas Station Cost: {env_params_optimal['gas_station_cost']}")
    console.print(f"  Toll Base Cost: {env_params_optimal['toll_base_cost']}")
    console.print(f"  Max Steps Per Episode: {max_steps_for_env}")

    env = TruckRoutingEnv(
        map_object=map_obj,
        # Sá»­ dá»¥ng giÃ¡ trá»‹ tá»‘i Æ°u thay vÃ¬ easy_params
        max_fuel_config=max_fuel_val, # Truyá»n max_fuel Ä‘Ã£ xÃ¡c Ä‘á»‹nh
        initial_fuel_config=env_params_optimal['initial_fuel'],
        initial_money_config=env_params_optimal['initial_money'],
        fuel_per_move_config=env_params_optimal['fuel_per_move'],
        gas_station_cost_config=env_params_optimal['gas_station_cost'],
        toll_base_cost_config=env_params_optimal['toll_base_cost'],
        max_steps_per_episode=max_steps_for_env 
    )
    return env

def create_agent(env, map_size, use_advanced, log_dir):
    """
    Táº¡o agent RL vá»›i tham sá»‘ tá»‘i Æ°u
    
    Args:
        env: MÃ´i trÆ°á»ng RL
        map_size: KÃ­ch thÆ°á»›c báº£n Ä‘á»“
        use_advanced: Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nÃ¢ng cao
        log_dir: ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c log Ä‘Ã£ Ä‘Æ°á»£c táº¡o bá»Ÿi hÃ m gá»i
    
    Returns:
        agent: Äá»‘i tÆ°á»£ng DQNAgentTrainer
    """
    # ThÆ° má»¥c log Ä‘Æ°á»£c cung cáº¥p bá»Ÿi hÃ m gá»i vÃ  Ä‘Ã£ Ä‘Æ°á»£c táº¡o
    # Path(log_dir).mkdir(parents=True, exist_ok=True) # DÃ²ng nÃ y khÃ´ng cáº§n thiáº¿t ná»¯a
    
    # Táº¡o agent
    agent = DQNAgentTrainer(env=env, log_dir=log_dir)
    
    # Láº¥y siÃªu tham sá»‘ tá»‘i Æ°u
    hyperparams = OPTIMAL_HYPERPARAMS.get(map_size, OPTIMAL_HYPERPARAMS[10])
    
    # Cáº¥u hÃ¬nh cho agent
    if use_advanced:
        # Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nÃ¢ng cao: Double DQN, Dueling Network, PER
        agent.create_model(
            learning_rate=hyperparams["learning_rate"],
            buffer_size=hyperparams["buffer_size"], 
            learning_starts=hyperparams["learning_starts"],
            batch_size=hyperparams["batch_size"],
            tau=hyperparams["tau"],
            gamma=hyperparams["gamma"],
            train_freq=hyperparams["train_freq"],
            gradient_steps=1,
            target_update_interval=hyperparams["target_update_interval"],
            exploration_fraction=hyperparams["exploration_fraction"],
            exploration_initial_eps=hyperparams["exploration_initial_eps"],
            exploration_final_eps=hyperparams["exploration_final_eps"],
            use_double_dqn=True,
            use_dueling_network=True,
            use_prioritized_replay=True,
            prioritized_replay_alpha=0.6,
            prioritized_replay_beta0=0.4
        )
    else:
        # Sá»­ dá»¥ng DQN cÆ¡ báº£n
        agent.create_model(
            learning_rate=hyperparams["learning_rate"],
            buffer_size=hyperparams["buffer_size"], 
            learning_starts=hyperparams["learning_starts"],
            batch_size=hyperparams["batch_size"],
            tau=hyperparams["tau"],
            gamma=hyperparams["gamma"],
            train_freq=hyperparams["train_freq"],
            target_update_interval=hyperparams["target_update_interval"],
            exploration_fraction=hyperparams["exploration_fraction"],
            exploration_initial_eps=hyperparams["exploration_initial_eps"],
            exploration_final_eps=hyperparams["exploration_final_eps"]
        )
    
    return agent

def train_agent(agent: DQNAgentTrainer, total_timesteps, map_size, callback=None):
    """Huáº¥n luyá»‡n agent Ä‘Ã£ Ä‘Æ°á»£c táº¡o."""
    console.print(f"[info]Báº¯t Ä‘áº§u huáº¥n luyá»‡n agent vá»›i {total_timesteps} timesteps...[/info]")
    agent.train(total_timesteps=total_timesteps, callback=callback)
    console.print("[green]âœ“[/green] Huáº¥n luyá»‡n agent hoÃ n thÃ nh.")

def evaluate_agent(agent: DQNAgentTrainer, map_size, num_episodes=10, eval_map_obj=None):
    """ÄÃ¡nh giÃ¡ nhanh agent báº±ng cÃ¡ch sá»­ dá»¥ng evaluate_robust_performance vá»›i ká»‹ch báº£n tá»‘i Æ°u.
    HÃ m nÃ y Ä‘Æ°á»£c giá»¯ láº¡i cho má»¥c Ä‘Ã­ch Ä‘Ã¡nh giÃ¡ nhanh hoáº·c gá»¡ lá»—i.
    """
    console.print(f"[info]ÄÃ¡nh giÃ¡ nhanh agent (evaluate_agent) trÃªn map_size={map_size} vá»›i {num_episodes} episodes...[/info]")
    
    if eval_map_obj is None:
        console.print("[warning]KhÃ´ng cÃ³ báº£n Ä‘á»“ Ä‘Ã¡nh giÃ¡ cá»¥ thá»ƒ cho evaluate_agent, táº¡o báº£n Ä‘á»“ ngáº«u nhiÃªn...[/warning]")
        eval_map_obj = Map.generate_random(map_size, 0.05, 0.05, 0.1)
        # Äáº£m báº£o start/end Ä‘Æ°á»£c thiáº¿t láº­p Ä‘Ãºng trÃªn map_obj nÃ y
        if not eval_map_obj.ensure_start_end_connected(): # ensure_start_end_connected cÃ³ thá»ƒ tráº£ vá» False
            console.print("[error]KhÃ´ng thá»ƒ táº¡o vá»‹ trÃ­ báº¯t Ä‘áº§u/káº¿t thÃºc há»£p lá»‡ trÃªn báº£n Ä‘á»“ ngáº«u nhiÃªn cho Ä‘Ã¡nh giÃ¡ (evaluate_agent).[/error]")
            return { 
                "overall_score": 0,
                "avg_success_rate": 0,
                "avg_reward_overall": 0,
                "avg_path_length_overall": 0,
                "detailed_results_by_scenario": {}
            } 

    # Táº¡o mÃ´i trÆ°á»ng Ä‘Ã¡nh giÃ¡.
    eval_env = create_environment(eval_map_obj, map_size) 
    
    # Chá»‰ sá»­ dá»¥ng ká»‹ch báº£n tá»‘i Æ°u cho viá»‡c Ä‘Ã¡nh giÃ¡ nhanh nÃ y
    # LÆ°u Ã½: get_optimal_env_scenario cáº§n map_size, khÃ´ng pháº£i eval_env.map_size trá»±c tiáº¿p á»Ÿ Ä‘Ã¢y
    # vÃ¬ eval_env cÃ³ thá»ƒ chÆ°a cÃ³ map_size náº¿u map_obj khÃ´ng há»£p lá»‡.
    quick_eval_scenario = get_optimal_env_scenario(eval_map_obj.size) # Sá»­ dá»¥ng eval_map_obj.size
    
    console.print(f"[info]Sá»­ dá»¥ng ká»‹ch báº£n Ä‘Ã¡nh giÃ¡ nhanh: {quick_eval_scenario.get('name')}[/info]")

    robust_metrics = evaluate_robust_performance(
        agent_model=agent,
        eval_env=eval_env, 
        num_episodes_per_scenario=num_episodes, 
        scenarios=[quick_eval_scenario] 
    )

    # KhÃ´ng cáº§n in láº¡i cÃ¡c metrics á»Ÿ Ä‘Ã¢y vÃ¬ evaluate_robust_performance Ä‘Ã£ in ráº¥t chi tiáº¿t.
    # Chá»‰ cáº§n tráº£ vá» káº¿t quáº£.
    return robust_metrics

def evaluate_robust_performance(agent_model: DQNAgentTrainer, eval_env: TruckRoutingEnv, 
                                num_episodes_per_scenario=5, scenarios=None,
                                outer_rich_progress_active: bool = False):
    """
    ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t cá»§a agent trÃªn nhiá»u ká»‹ch báº£n mÃ´i trÆ°á»ng.
    Sá»­ dá»¥ng láº¡i eval_env vÃ  gá»i reset vá»›i evaluation_params.
    Args:
        agent_model: Model agent Ä‘Ã£ huáº¥n luyá»‡n.
        eval_env: MÃ´i trÆ°á»ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡.
        num_episodes_per_scenario: Sá»‘ episodes Ä‘á»ƒ cháº¡y cho má»—i ká»‹ch báº£n.
        scenarios: Danh sÃ¡ch cÃ¡c ká»‹ch báº£n Ä‘á»ƒ Ä‘Ã¡nh giÃ¡. Náº¿u None, dÃ¹ng default.
        outer_rich_progress_active: True náº¿u cÃ³ má»™t Rich Progress bar bÃªn ngoÃ i Ä‘ang cháº¡y.
    """
    if scenarios is None:
        current_scenarios = list(DEFAULT_EVALUATION_SCENARIOS) 
        current_scenarios.append(get_optimal_env_scenario(eval_env.map_size))
    else:
        current_scenarios = scenarios

    total_episodes = 0
    total_successes = 0
    all_episode_rewards = []
    all_episode_path_lengths = []
    all_episode_money_spent = []
    all_episode_fuel_consumed = []
    
    detailed_results_by_scenario = {}

    console.print(f"[info]Báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t trÃªn {len(current_scenarios)} ká»‹ch báº£n...[/info]")

    try: # Bá»c vÃ²ng láº·p ká»‹ch báº£n
        for scenario_idx, scenario in enumerate(current_scenarios):
            scenario_name = scenario.get("name", f"Scenario {scenario_idx + 1}")
            console.print(f"  [info]Äang Ä‘Ã¡nh giÃ¡ ká»‹ch báº£n ({scenario_idx+1}/{len(current_scenarios)}): {scenario_name}[/info]")
            
            progress_bar_description = f"Episodes cho '{shorten_text(scenario_name, 30)}'"
            episode_run_results = None

            if not outer_rich_progress_active and RICH_AVAILABLE:
                with Progress(
                    SpinnerColumn(),
                    TextColumn("[progress.description]{task.description}"),
                    BarColumn(),
                    TaskProgressColumn(),
                    TimeRemainingColumn(),
                    console=console,
                    transient=True 
                ) as progress:
                    task_id = progress.add_task(progress_bar_description, total=num_episodes_per_scenario)
                    episode_run_results = _run_scenario_episodes(
                        eval_env, agent_model, scenario, num_episodes_per_scenario,
                        scenario_name, # scenario_name_logging
                        rich_progress=progress, rich_task_id=task_id
                    )
            else:
                episode_run_results = _run_scenario_episodes(
                    eval_env, agent_model, scenario, num_episodes_per_scenario,
                    scenario_name # scenario_name_logging
                )
            
            scenario_successes_count = episode_run_results["success_count"]
            scenario_rewards_list = episode_run_results["rewards_list"]
            scenario_path_lengths_list = episode_run_results["path_lengths_list"]
            scenario_money_spent_list = episode_run_results["money_spent_list"]
            scenario_fuel_consumed_list = episode_run_results["fuel_consumed_list"]
            
            total_successes += scenario_successes_count
            all_episode_rewards.extend(scenario_rewards_list)
            all_episode_path_lengths.extend(scenario_path_lengths_list)
            all_episode_money_spent.extend(scenario_money_spent_list)
            all_episode_fuel_consumed.extend(scenario_fuel_consumed_list)

            detailed_results_by_scenario[scenario_name] = {
                "success_rate": scenario_successes_count / num_episodes_per_scenario if num_episodes_per_scenario > 0 else 0,
                "avg_reward": np.mean(scenario_rewards_list) if scenario_rewards_list else 0,
                "avg_path_length": np.mean(scenario_path_lengths_list) if scenario_path_lengths_list else 0,
                "avg_money_spent": np.mean(scenario_money_spent_list) if scenario_money_spent_list else 0,
                "avg_fuel_consumed": np.mean(scenario_fuel_consumed_list) if scenario_fuel_consumed_list else 0,
                "rewards_list": scenario_rewards_list,
                "path_lengths_list": scenario_path_lengths_list
            }
            console.print(f"  [green]âœ“[/green] Ká»‹ch báº£n '{scenario_name}': SR={detailed_results_by_scenario[scenario_name]['success_rate']:.2f}, AvgRew={detailed_results_by_scenario[scenario_name]['avg_reward']:.2f}")

    except Exception as e_eval_robust:
        console.print(f"[bold red]Lá»–I TRONG evaluate_robust_performance:[/bold red]")
        console.print(f"[red]{str(e_eval_robust)}[/red]")
        if RICH_AVAILABLE:
            console.print_exception(show_locals=False)
        else:
            traceback.print_exc()
        # Tráº£ vá» káº¿t quáº£ lá»—i Ä‘á»ƒ pipeline chÃ­nh cÃ³ thá»ƒ xá»­ lÃ½
        return {
            "overall_score": 0,
            "avg_success_rate": 0,
            "avg_reward_overall": 0,
            "avg_path_length_overall": 0,
            "detailed_results_by_scenario": {},
            "error": str(e_eval_robust)
        }

    avg_success_rate = total_successes / total_episodes if total_episodes > 0 else 0
    avg_reward_overall = np.mean(all_episode_rewards) if all_episode_rewards else 0
    avg_path_length_overall = np.mean(all_episode_path_lengths) if all_episode_path_lengths else 0
    avg_money_spent_overall = np.mean(all_episode_money_spent) if all_episode_money_spent else 0
    avg_fuel_consumed_overall = np.mean(all_episode_fuel_consumed) if all_episode_fuel_consumed else 0
    
    score_reward_component = np.tanh(avg_reward_overall / 100) 
    score_path_component = 0
    if avg_path_length_overall > 0 and eval_env.max_steps_per_episode > 0:
        # Path length should be non-zero if successful, use max_steps as a rough normalizer
        normalized_path = avg_path_length_overall / eval_env.max_steps_per_episode
        score_path_component = 1 - normalized_path 
        score_path_component = max(-1, min(1, score_path_component)) # clamp between -1 and 1

    overall_score = (avg_success_rate * 0.6) + (score_reward_component * 0.2) + (score_path_component * 0.2)
    overall_score = max(0, min(1, overall_score)) 

    console.print(f"[highlight]ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t hoÃ n thÃ nh:[/highlight]")
    console.print(f"  Tá»· lá»‡ thÃ nh cÃ´ng TB (qua cÃ¡c ká»‹ch báº£n): {avg_success_rate:.2%}")
    console.print(f"  Pháº§n thÆ°á»Ÿng TB tá»•ng thá»ƒ: {avg_reward_overall:.2f}")
    console.print(f"  Äá»™ dÃ i Ä‘Æ°á»ng Ä‘i TB tá»•ng thá»ƒ: {avg_path_length_overall:.2f}")
    console.print(f"  Chi tiÃªu tiá»n TB tá»•ng thá»ƒ: {avg_money_spent_overall:.2f}")
    console.print(f"  TiÃªu thá»¥ nhiÃªn liá»‡u TB tá»•ng thá»ƒ: {avg_fuel_consumed_overall:.2f}")
    console.print(f"  [bold]Äiá»ƒm hiá»‡u nÄƒng tá»•ng há»£p (0-1): {overall_score:.4f}[/bold]")

    return {
        "overall_score": overall_score,
        "avg_success_rate": avg_success_rate,
        "avg_reward_overall": avg_reward_overall,
        "avg_path_length_overall": avg_path_length_overall,
        "avg_money_spent_overall": avg_money_spent_overall,
        "avg_fuel_consumed_overall": avg_fuel_consumed_overall,
        "detailed_results_by_scenario": detailed_results_by_scenario
    }

# Helper function to run evaluation episodes for a single scenario
def _run_scenario_episodes(eval_env: TruckRoutingEnv, agent_model: DQNAgentTrainer, scenario_params: dict, 
                           num_episodes: int, scenario_name_logging: str, 
                           rich_progress=None, rich_task_id=None):
    """
    Runs evaluation episodes for a single scenario and collects metrics.
    Logs progress to console if rich_progress is None and an outer Rich display is active.
    """
    scenario_successes_count = 0
    scenario_rewards_list = []
    scenario_path_lengths_list = []
    scenario_money_spent_list = []
    scenario_fuel_consumed_list = []

    try: # Bá»c vÃ²ng láº·p episodes
        for episode_idx in range(num_episodes):
            if rich_progress is None: 
                if RICH_AVAILABLE and hasattr(console, 'is_live') and console.is_live:
                    if num_episodes <=5 or (episode_idx + 1) % max(1, num_episodes // 3) == 0 or episode_idx == num_episodes - 1:
                        console.print(f"    Ká»‹ch báº£n '{shorten_text(scenario_name_logging, 25)}': Äang cháº¡y episode {episode_idx + 1}/{num_episodes}...")
                elif not RICH_AVAILABLE: 
                    if (episode_idx + 1) % max(1, num_episodes // 5) == 0 or episode_idx == num_episodes - 1:
                        print(f"    Ká»‹ch báº£n '{scenario_name_logging}': Episode {episode_idx + 1}/{num_episodes}")
            
            obs, info = eval_env.reset(evaluation_params=scenario_params) 
            terminated = False
            truncated = False
            episode_reward = 0.0
            episode_length = 0
            initial_money_for_episode = eval_env.current_money 
            initial_fuel_for_episode = eval_env.current_fuel   

            while not (terminated or truncated):
                predicted_output = agent_model.predict_action(obs)
                if isinstance(predicted_output, tuple):
                    action = predicted_output[0]
                else:
                    action = predicted_output
                
                if hasattr(action, 'item'): 
                    action = action.item()
                
                obs, reward, term, trunc, info = eval_env.step(action) 
                terminated = term
                truncated = trunc
                episode_reward += reward
                episode_length += 1
            
            if info.get("termination_reason") == "den_dich":
                scenario_successes_count += 1
            
            scenario_rewards_list.append(episode_reward)
            actual_path_length = episode_length if info.get("termination_reason") == "den_dich" else eval_env.max_steps_per_episode
            scenario_path_lengths_list.append(actual_path_length)
            
            money_spent_episode = initial_money_for_episode - eval_env.current_money
            current_fuel_after_episode = eval_env.current_fuel 
            fuel_consumed_episode = initial_fuel_for_episode - current_fuel_after_episode
            scenario_money_spent_list.append(money_spent_episode)
            scenario_fuel_consumed_list.append(fuel_consumed_episode)
            
            if rich_progress and rich_task_id:
                rich_progress.update(rich_task_id, advance=1)

    except Exception as e_scenario_run:
        console.print(f"[bold red]Lá»–I TRONG _run_scenario_episodes (ká»‹ch báº£n: {scenario_name_logging}):[/bold red]")
        console.print(f"[red]{str(e_scenario_run)}[/red]")
        if RICH_AVAILABLE:
            console.print_exception(show_locals=False)
        else:
            traceback.print_exc()
        # Váº«n tráº£ vá» nhá»¯ng gÃ¬ Ä‘Ã£ thu tháº­p Ä‘Æ°á»£c, cÃ³ thá»ƒ khÃ´ng Ä‘áº§y Ä‘á»§
        # Hoáº·c cÃ³ thá»ƒ raise láº¡i lá»—i náº¿u muá»‘n dá»«ng háº³n evaluate_robust_performance

    return {
        "success_count": scenario_successes_count,
        "rewards_list": scenario_rewards_list,
        "path_lengths_list": scenario_path_lengths_list,
        "money_spent_list": scenario_money_spent_list,
        "fuel_consumed_list": scenario_fuel_consumed_list
    }

def shorten_text(text, max_length):
    return text if len(text) <= max_length else text[:max_length-3] + "..."

# ThÃªm háº±ng sá»‘ cho thÆ° má»¥c lÆ°u model "tá»‘t nháº¥t"
BEST_ROBUST_MODELS_DIR = MODELS_DIR / "best_robust_by_type"
BEST_ROBUST_MODELS_DIR.mkdir(parents=True, exist_ok=True)

# Callback tÃ¹y chá»‰nh cho Rich Progress Bar trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n SB3
class RichProgressSB3Callback(BaseCallback):
    """
    Callback tÃ¹y chá»‰nh cho Stable Baselines3 Ä‘á»ƒ cáº­p nháº­t Rich Progress Bar.
    """
    def __init__(self, total_training_steps: int, 
                 pipeline_progress_callback, 
                 pipeline_progress_start_percent: int, 
                 pipeline_progress_span_percent: int, # Tá»•ng % dÃ nh cho training
                 verbose: int = 0):
        super().__init__(verbose)
        self.total_training_steps = total_training_steps
        self.pipeline_progress_callback = pipeline_progress_callback
        self.pipeline_progress_start_percent = pipeline_progress_start_percent
        self.pipeline_progress_span_percent = pipeline_progress_span_percent
        self.training_status_message_template = "Huáº¥n luyá»‡n: {current_steps}/{total_steps} ({percent_done:.1f}%)"

    def _on_step(self) -> bool:
        if self.pipeline_progress_callback:
            # TÃ­nh toÃ¡n % hoÃ n thÃ nh cá»§a chá»‰ riÃªng phase huáº¥n luyá»‡n
            training_completion_fraction = self.num_timesteps / self.total_training_steps
            
            # TÃ­nh toÃ¡n % tá»•ng thá»ƒ trÃªn pipeline progress bar
            current_pipeline_percent = self.pipeline_progress_start_percent + \
                                       (training_completion_fraction * self.pipeline_progress_span_percent)
            
            status_message = self.training_status_message_template.format(
                current_steps=self.num_timesteps,
                total_steps=self.total_training_steps,
                percent_done=training_completion_fraction * 100
            )
            
            self.pipeline_progress_callback(current_pipeline_percent, status_message)
        return True

def run_training_pipeline(map_size, num_maps=10, training_steps=50000, use_advanced=False, render=False, progress_callback=None, outer_rich_progress_active: bool = False):
    """Cháº¡y toÃ n bá»™ pipeline huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡."""
    # Define progress milestones
    P_START = 0
    P_MAP_GENERATION_TRAIN_END = 10  # Táº¡o map train xong
    P_MAP_GENERATION_EVAL_END = 15   # Táº¡o map eval xong
    P_ENV_CREATION_END = 20          # Táº¡o mÃ´i trÆ°á»ng xong
    P_AGENT_CREATION_END = 25        # Táº¡o agent xong
    P_TRAINING_START = 25            # Báº¯t Ä‘áº§u huáº¥n luyá»‡n
    P_TRAINING_SPAN = 50             # % dÃ nh cho training
    P_TRAINING_END = P_TRAINING_START + P_TRAINING_SPAN  # Huáº¥n luyá»‡n xong
    P_SESSION_MODEL_SAVE_END = P_TRAINING_END + 5  # LÆ°u model session xong
    P_NEW_MODEL_EVAL_END = P_SESSION_MODEL_SAVE_END + 10  # ÄÃ¡nh giÃ¡ model má»›i xong
    P_OLD_MODEL_EVAL_END = P_NEW_MODEL_EVAL_END + 5  # ÄÃ¡nh giÃ¡ model cÅ© xong
    P_PIPELINE_END = 100             # HoÃ n thÃ nh

    try:  # Bá»c toÃ n bá»™ pipeline
        console.print(f"[title]â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[/title]")
        console.print(f"[title]â•‘    Báº®T Äáº¦U PIPELINE HUáº¤N LUYá»†N Tá»° Äá»˜NG RL     â•‘[/title]")
        console.print(f"[title]â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[/title]")
        console.print(f"[info]PhiÃªn lÃ m viá»‡c: {SESSION_ID}[/info]")
        console.print(f"[info]Cháº¡y pipeline huáº¥n luyá»‡n cho map_size={map_size}[/info]")
        console.print(f"  Sá»‘ báº£n Ä‘á»“ train/eval/test: {num_maps}")
        console.print(f"  Sá»‘ bÆ°á»›c huáº¥n luyá»‡n: {training_steps}")
        console.print(f"  Sá»­ dá»¥ng ká»¹ thuáº­t nÃ¢ng cao: {'CÃ³' if use_advanced else 'KhÃ´ng'}")

        # --- 1. Thiáº¿t láº­p thÆ° má»¥c ---    
        session_log_dir = LOGS_DIR / SESSION_ID / f"map_size_{map_size}"
        session_models_dir = MODELS_DIR / SESSION_ID / f"map_size_{map_size}"
        session_maps_dir = MAPS_DIR / SESSION_ID / f"map_size_{map_size}"
        
        session_log_dir.mkdir(parents=True, exist_ok=True)
        session_models_dir.mkdir(parents=True, exist_ok=True)
        session_maps_dir.mkdir(parents=True, exist_ok=True)

        # --- 2. Táº¡o báº£n Ä‘á»“ huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ ---
        console.print("[step]BÆ°á»›c 1 & 2: Táº¡o báº£n Ä‘á»“ huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡...[/step]")
        map_progress_callback_wrapper = progress_callback if progress_callback else lambda p, m: None
        
        if progress_callback:
            progress_callback(10, f"Äang táº¡o {num_maps} báº£n Ä‘á»“ huáº¥n luyá»‡n size {map_size}x{map_size}...")

        map_train_paths = generate_maps(map_size, num_maps=num_maps, map_types=["train"], 
                                      map_save_dir=session_maps_dir, 
                                      progress_callback=map_progress_callback_wrapper)
        if not map_train_paths:
            console.print("[error]KhÃ´ng thá»ƒ táº¡o báº£n Ä‘á»“ huáº¥n luyá»‡n. Dá»«ng pipeline.[/error]")
            return None
        console.print(f"[green]âœ“[/green] ÄÃ£ táº¡o {len(map_train_paths)} báº£n Ä‘á»“ huáº¥n luyá»‡n.")

        if progress_callback:
            progress_callback(15, f"Äang táº¡o {max(1, num_maps // 5)} báº£n Ä‘á»“ Ä‘Ã¡nh giÃ¡ size {map_size}x{map_size}...")

        map_eval_paths = generate_maps(map_size, num_maps=max(1, num_maps // 5), map_types=["eval"], 
                                     map_save_dir=session_maps_dir, 
                                     progress_callback=map_progress_callback_wrapper)
        console.print(f"[green]âœ“[/green] ÄÃ£ táº¡o {len(map_eval_paths)} báº£n Ä‘á»“ Ä‘Ã¡nh giÃ¡.")

        train_map_obj = Map.load(map_train_paths[0])  # Sá»­ dá»¥ng báº£n Ä‘á»“ Ä‘áº§u tiÃªn lÃ m cÆ¡ sá»Ÿ
        if not train_map_obj:  # Kiá»ƒm tra náº¿u Map.load tháº¥t báº¡i
            console.print(f"[error]KhÃ´ng thá»ƒ táº£i báº£n Ä‘á»“ huáº¥n luyá»‡n chÃ­nh: {map_train_paths[0]}. Dá»«ng pipeline.[/error]")
            return {
                "best_model_path": None,
                "best_model_performance": None,
                "session_model_path": None,
                "session_model_performance": None,
                "error": f"Failed to load main training map: {map_train_paths[0]}"
            }

        # Get map name for model identification
        map_specific_name_part = Path(map_train_paths[0]).stem
        map_type_folder_name = f"map_file_{map_specific_name_part}"
        
        # Setup best model directory
        specific_best_model_dir = BEST_ROBUST_MODELS_DIR / map_type_folder_name
        specific_best_model_dir.mkdir(parents=True, exist_ok=True)
        best_model_path_for_type = specific_best_model_dir / "best_robust_rl_model.zip"

        # --- 3. Táº¡o mÃ´i trÆ°á»ng RL ---
        console.print("[step]BÆ°á»›c 3: Táº¡o mÃ´i trÆ°á»ng RL...[/step]")
        if progress_callback:
            progress_callback(P_ENV_CREATION_END - 2, "Táº¡o mÃ´i trÆ°á»ng RL...")  # Cáº­p nháº­t gáº§n cuá»‘i bÆ°á»›c nÃ y
        
        env = create_environment(train_map_obj, map_size, "human" if render else None)
        console.print(f"[green]âœ“[/green] MÃ´i trÆ°á»ng RL Ä‘Ã£ Ä‘Æ°á»£c táº¡o.")
        if progress_callback:
            progress_callback(P_ENV_CREATION_END, "MÃ´i trÆ°á»ng RL Ä‘Ã£ táº¡o.")

        # --- 4. Táº¡o Agent --- 
        console.print("[step]BÆ°á»›c 4: Táº¡o agent RL...[/step]")
        if progress_callback:
            progress_callback(P_AGENT_CREATION_END - 2, "Táº¡o RL agent...")

        # Sá»­ dá»¥ng cÃ¡c siÃªu tham sá»‘ tá»‘i Æ°u
        agent_hyperparams = OPTIMAL_HYPERPARAMS.get(map_size, OPTIMAL_HYPERPARAMS[8])
        agent = create_agent(env, map_size, use_advanced, log_dir=str(session_log_dir))
        console.print(f"[green]âœ“[/green] Agent Ä‘Ã£ Ä‘Æ°á»£c táº¡o.")
        if progress_callback:
            progress_callback(P_AGENT_CREATION_END, "RL Agent Ä‘Ã£ táº¡o.")

        # --- 5. Huáº¥n luyá»‡n Agent --- 
        console.print("[step]BÆ°á»›c 5: Huáº¥n luyá»‡n agent...[/step]")
        if progress_callback:
            progress_callback(P_TRAINING_START, f"Chuáº©n bá»‹ huáº¥n luyá»‡n ({training_steps} bÆ°á»›c)...")
        
        training_start_time = time.time()
        
        sb3_callback_list = []
        if progress_callback:
            rich_sb3_callback = RichProgressSB3Callback(
                total_training_steps=training_steps,
                pipeline_progress_callback=progress_callback,
                pipeline_progress_start_percent=P_TRAINING_START,
                pipeline_progress_span_percent=P_TRAINING_SPAN,
                verbose=0 
            )
            sb3_callback_list.append(rich_sb3_callback)

        agent.train(total_timesteps=training_steps, callback=sb3_callback_list[0] if sb3_callback_list else None) 

        training_duration = time.time() - training_start_time
        console.print(f"[green]âœ“[/green] Huáº¥n luyá»‡n hoÃ n thÃ nh sau {training_duration:.2f} giÃ¢y.")
        
        if progress_callback:
            progress_callback(P_TRAINING_END, f"Huáº¥n luyá»‡n xong. Äang lÆ°u model phiÃªn...")
        
        current_session_model_name = f"model_session_{SESSION_ID}_{map_specific_name_part}_steps_{training_steps}.zip"
        current_session_model_path = session_models_dir / current_session_model_name
        agent.save_model(str(current_session_model_path))  # Äáº£m báº£o truyá»n string
        console.print(f"[info]MÃ´ hÃ¬nh huáº¥n luyá»‡n trong phiÃªn nÃ y Ä‘Æ°á»£c lÆ°u táº¡i: {current_session_model_path}[/info]")

        # --- 6. ÄÃ¡nh giÃ¡ Agent Ä‘Ã£ huáº¥n luyá»‡n vÃ  so sÃ¡nh --- 
        console.print("[step]BÆ°á»›c 6: ÄÃ¡nh giÃ¡ agent vÃ  so sÃ¡nh vá»›i mÃ´ hÃ¬nh tá»‘t nháº¥t hiá»‡n cÃ³...[/step]")
        
        if progress_callback:
            progress_callback(P_SESSION_MODEL_SAVE_END + 2, "ÄÃ¡nh giÃ¡ model má»›i...")
        
        # Táº£i báº£n Ä‘á»“ Ä‘Ã¡nh giÃ¡ hoáº·c dÃ¹ng báº£n Ä‘á»“ huáº¥n luyá»‡n náº¿u khÃ´ng cÃ³ báº£n Ä‘á»“ Ä‘Ã¡nh giÃ¡
        eval_map_obj_for_comparison = None
        if map_eval_paths and map_eval_paths[0]:
            eval_map_obj_for_comparison = Map.load(map_eval_paths[0])
        
        if not eval_map_obj_for_comparison:
            console.print(f"[warning]KhÃ´ng táº£i Ä‘Æ°á»£c báº£n Ä‘á»“ Ä‘Ã¡nh giÃ¡ tá»« {map_eval_paths[0] if map_eval_paths else 'N/A'}. Sá»­ dá»¥ng báº£n Ä‘á»“ huáº¥n luyá»‡n Ä‘á»ƒ Ä‘Ã¡nh giÃ¡.[/warning]")
            eval_map_obj_for_comparison = train_map_obj
        
        eval_env_for_comparison = create_environment(eval_map_obj_for_comparison, map_size)

        console.print(f"[info]ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh vá»«a huáº¥n luyá»‡n (tá»« phiÃªn {SESSION_ID})...[/info]")
        
        new_model_performance = evaluate_robust_performance(
            agent, eval_env_for_comparison, 
            num_episodes_per_scenario=10, 
            scenarios=None,
            outer_rich_progress_active=outer_rich_progress_active
        ) 
        
        if progress_callback:
            progress_callback(P_NEW_MODEL_EVAL_END, "ÄÃ¡nh giÃ¡ model má»›i hoÃ n táº¥t.")
        
        final_best_model_path = None
        final_best_model_performance = None

        if best_model_path_for_type.exists():
            console.print(f"[info]Äang táº£i mÃ´ hÃ¬nh tá»‘t nháº¥t hiá»‡n cÃ³ tá»«: {best_model_path_for_type} Ä‘á»ƒ so sÃ¡nh...[/info]")
            if progress_callback:
                progress_callback(P_NEW_MODEL_EVAL_END + 2, "ÄÃ¡nh giÃ¡ model tá»‘t nháº¥t hiá»‡n cÃ³...")
            old_agent = DQNAgentTrainer(env=eval_env_for_comparison) 
            try:
                old_agent.load_model(str(best_model_path_for_type))
                console.print("[info]ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh tá»‘t nháº¥t hiá»‡n cÃ³...[/info]")
                old_model_performance = evaluate_robust_performance(
                    old_agent, eval_env_for_comparison, 
                    num_episodes_per_scenario=10,
                    scenarios=None,
                    outer_rich_progress_active=outer_rich_progress_active
                )
                if progress_callback:
                    progress_callback(P_OLD_MODEL_EVAL_END, "So sÃ¡nh model hoÃ n táº¥t.")
                
                console.print(f"  Äiá»ƒm mÃ´ hÃ¬nh má»›i: {new_model_performance['overall_score']:.4f}")
                console.print(f"  Äiá»ƒm mÃ´ hÃ¬nh cÅ©: {old_model_performance['overall_score']:.4f}")

                if new_model_performance["overall_score"] > old_model_performance["overall_score"]:
                    console.print(f"[success]MÃ´ hÃ¬nh má»›i Tá»T HÆ N. Äang lÆ°u vÃ o: {best_model_path_for_type}[/success]")
                    agent.save_model(str(best_model_path_for_type))  # Ghi Ä‘Ã¨ mÃ´ hÃ¬nh tá»‘t nháº¥t
                    final_best_model_path = best_model_path_for_type
                    final_best_model_performance = new_model_performance
                else:
                    console.print(f"[warning]MÃ´ hÃ¬nh má»›i KHÃ”NG cáº£i thiá»‡n. Giá»¯ láº¡i mÃ´ hÃ¬nh cÅ© táº¡i: {best_model_path_for_type}[/warning]")
                    final_best_model_path = best_model_path_for_type  # Váº«n lÃ  Ä‘Æ°á»ng dáº«n cÅ©
                    final_best_model_performance = old_model_performance  # Performance cá»§a model cÅ© tá»‘t hÆ¡n
            except Exception as e:
                console.print(f"[error]Lá»—i khi táº£i hoáº·c Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh cÅ©: {e}. Sáº½ lÆ°u mÃ´ hÃ¬nh má»›i.[/error]")
                agent.save_model(str(best_model_path_for_type))
                final_best_model_path = best_model_path_for_type
                final_best_model_performance = new_model_performance
        else:
            console.print(f"[info]ChÆ°a cÃ³ mÃ´ hÃ¬nh tá»‘t nháº¥t nÃ o cho loáº¡i báº£n Ä‘á»“ '{map_type_folder_name}'. LÆ°u mÃ´ hÃ¬nh má»›i lÃ m tá»‘t nháº¥t.[/info]")
            agent.save_model(str(best_model_path_for_type))
            final_best_model_path = best_model_path_for_type
            final_best_model_performance = new_model_performance
        
        console.print("[step]BÆ°á»›c 7: HoÃ n thÃ nh pipeline vÃ  dá»n dáº¹p (náº¿u cÃ³)...[/step]")
        if progress_callback:
            progress_callback(P_PIPELINE_END, "Pipeline hoÃ n thÃ nh!")
        
        return {
            "best_model_path": str(final_best_model_path) if final_best_model_path else None,
            "best_model_performance": final_best_model_performance,
            "session_model_path": str(current_session_model_path),
            "session_model_performance": new_model_performance,
            "map_type_folder_name": map_type_folder_name
        }
    except Exception as e_pipeline:
        console.print(f"[bold red]Lá»–I NGHIÃŠM TRá»ŒNG TRONG PIPELINE HUáº¤N LUYá»†N:[/bold red]")
        console.print(f"[red]{str(e_pipeline)}[/red]")
        if RICH_AVAILABLE:  # traceback cÃ³ thá»ƒ dÃ i, chá»‰ in náº¿u cÃ³ Rich
            console.print_exception(show_locals=False)  # show_locals=True cÃ³ thá»ƒ quÃ¡ dÃ i
        else:
            traceback.print_exc()  # In traceback tiÃªu chuáº©n
        return {
            "best_model_path": None,
            "best_model_performance": None,
            "session_model_path": None,
            "session_model_performance": None,
            "error": str(e_pipeline),
            "map_type_folder_name": locals().get("map_type_folder_name", "unknown")
        }

def master_mode():
    """
    Cháº¿ Ä‘á»™ Master: Chá»‰ cáº§n nháº­p kÃ­ch thÆ°á»›c báº£n Ä‘á»“, tá»± Ä‘á»™ng tá»‘i Æ°u hÃ³a táº¥t cáº£ cÃ¡c tham sá»‘ khÃ¡c
    """
    if RICH_AVAILABLE:
        console.print("\n[bold cyan]MASTER MODE - Tá»° Äá»˜NG Tá»I Æ¯U HÃ“A[/bold cyan]")
        console.print("[bold yellow]Chá»‰ cáº§n nháº­p kÃ­ch thÆ°á»›c báº£n Ä‘á»“, má»i thá»© sáº½ Ä‘Æ°á»£c tá»± Ä‘á»™ng cáº¥u hÃ¬nh tá»‘i Æ°u![/bold yellow]")
        
        # Táº¡o báº£ng chá»n kÃ­ch thÆ°á»›c báº£n Ä‘á»“
        size_table = Table(box=box.SIMPLE, show_header=True)
        size_table.add_column("Option", header_style="bold cyan", style=COLORS["menu_number"], justify="center")
        size_table.add_column("KÃ­ch thÆ°á»›c", header_style="bold cyan", style=COLORS["menu_text"], justify="center")
        size_table.add_column("Má»©c Ä‘á»™ phá»©c táº¡p", header_style="bold cyan", style=COLORS["menu_text"], justify="center")
        size_table.add_column("Thá»i gian huáº¥n luyá»‡n", header_style="bold cyan", style=COLORS["menu_text"], justify="center")
        
        size_table.add_row("1", "8 x 8", "CÆ¡ báº£n", "~5-10 phÃºt")
        size_table.add_row("2", "9 x 9", "Trung bÃ¬nh", "~10-15 phÃºt")
        size_table.add_row("3", "10 x 10", "KhÃ³", "~15-25 phÃºt")
        size_table.add_row("4", "12 x 12", "Ráº¥t khÃ³", "~30-40 phÃºt")
        size_table.add_row("5", "15 x 15", "Cá»±c khÃ³", "~45-60 phÃºt")
        
        size_panel = Panel(
            size_table,
            title="[ CHá»ŒN KÃCH THÆ¯á»šC Báº¢N Äá»’ ]",
            title_align="center",
            border_style=COLORS["border"],
            padding=(1, 2)
        )
        console.print(size_panel)
        
        choice = Prompt.ask(
            "\n[bold cyan]Chá»n kÃ­ch thÆ°á»›c báº£n Ä‘á»“[/bold cyan]",
            choices=["1", "2", "3", "4", "5", "0"],
            default="1"
        )
        
        if choice == "0":
            return
            
        # Map tá»« lá»±a chá»n sang kÃ­ch thÆ°á»›c báº£n Ä‘á»“
        map_sizes = {
            "1": 8,
            "2": 9,
            "3": 10,
            "4": 12,
            "5": 15
        }
        
        map_size = map_sizes[choice]
        
        # Cáº¥u hÃ¬nh tá»‘i Æ°u tá»± Ä‘á»™ng dá»±a trÃªn kÃ­ch thÆ°á»›c
        # Sá»‘ lÆ°á»£ng báº£n Ä‘á»“ giáº£m khi kÃ­ch thÆ°á»›c tÄƒng
        if map_size <= 9:
            num_maps = 12
        elif map_size <= 10:
            num_maps = 10
        elif map_size <= 12:
            num_maps = 8
        else:
            num_maps = 5
            
        # Sá»‘ bÆ°á»›c huáº¥n luyá»‡n tÄƒng theo kÃ­ch thÆ°á»›c
        if map_size <= 8:
            training_steps = 125000  # Original: 50000
            use_advanced = False
        elif map_size <= 9:
            training_steps = 187500  # Original: 75000
            use_advanced = False
        elif map_size <= 10:
            training_steps = 250000  # Original: 100000
            use_advanced = True
        elif map_size <= 12:
            training_steps = 375000  # Original: 150000
            use_advanced = True
        else:
            training_steps = 500000  # Original: 200000
            use_advanced = True
            
        # Hiá»ƒn thá»‹ cáº¥u hÃ¬nh tá»‘i Æ°u Ä‘Ã£ chá»n
        config_table = Table(show_header=True, box=box.SIMPLE)
        config_table.add_column("Tham sá»‘", style="cyan")
        config_table.add_column("GiÃ¡ trá»‹", style="green")
        
        config_table.add_row("KÃ­ch thÆ°á»›c báº£n Ä‘á»“", f"{map_size}x{map_size}")
        config_table.add_row("Sá»‘ lÆ°á»£ng báº£n Ä‘á»“", f"{num_maps}")
        config_table.add_row("Sá»‘ bÆ°á»›c huáº¥n luyá»‡n", f"{training_steps:,}")
        config_table.add_row("Sá»­ dá»¥ng ká»¹ thuáº­t nÃ¢ng cao", "âœ… CÃ³" if use_advanced else "âŒ KhÃ´ng")
        
        hyperparams = OPTIMAL_HYPERPARAMS.get(map_size, OPTIMAL_HYPERPARAMS[10])
        env_params = OPTIMAL_ENV_PARAMS.get(map_size, OPTIMAL_ENV_PARAMS[10])
        
        config_table.add_row("Learning rate", f"{hyperparams['learning_rate']}")
        config_table.add_row("Replay buffer", f"{hyperparams['buffer_size']}")
        config_table.add_row("NhiÃªn liá»‡u ban Ä‘áº§u", f"{env_params['initial_fuel']}")
        
        config_panel = Panel(
            config_table,
            title="[ Cáº¤U HÃŒNH Tá»I Æ¯U ]",
            title_align="center",
            border_style=COLORS["border"],
            padding=(1, 2)
        )
        console.print(config_panel)
        
        # Hiá»ƒn thá»‹ thÃ´ng bÃ¡o tiáº¿n trÃ¬nh
        with console.status("[bold green]Äang chuáº©n bá»‹ huáº¥n luyá»‡n...", spinner="dots"):
            time.sleep(1.5)  # Táº¡o hiá»‡u á»©ng loading
        
        confirm = Confirm.ask("[bold yellow]XÃ¡c nháº­n huáº¥n luyá»‡n vá»›i cáº¥u hÃ¬nh tá»‘i Æ°u?[/bold yellow]")
        
        if confirm:
            console.print("[bold green]Báº¯t Ä‘áº§u huáº¥n luyá»‡n tá»‘i Æ°u cho báº£n Ä‘á»“ kÃ­ch thÆ°á»›c " + 
                        f"{map_size}x{map_size}...[/bold green]")
            
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(bar_width=40, style=COLORS["progress"]),
                TaskProgressColumn(),
                TimeRemainingColumn(),
                TextColumn("[cyan]{task.fields[status]}", justify="right"),
                console=console,
                expand=False
            ) as progress:
                task = progress.add_task(
                    f"[bold cyan]Huáº¥n luyá»‡n Master cho báº£n Ä‘á»“ {map_size}x{map_size}[/bold cyan]", 
                    total=100,
                    status="Chuáº©n bá»‹..."
                )
                
                # Cáº­p nháº­t tráº¡ng thÃ¡i khi cháº¡y pipeline
                def progress_update_callback(percent, status):
                    progress.update(task, completed=10 + percent * 0.9, status=status)
                
                progress.update(task, completed=0, status="Khá»Ÿi táº¡o pipeline...") 
                progress_update_callback(0, "Táº¡o báº£n Ä‘á»“...") # Directly call the locally defined callback
                
                # Cháº¡y pipeline huáº¥n luyá»‡n vá»›i má»™t cá» hiá»‡u Ä‘áº·c biá»‡t Ä‘á»ƒ trÃ¡nh xung Ä‘á»™t progress bar
                results = run_training_pipeline(
                    map_size=map_size,
                    num_maps=num_maps,
                    training_steps=training_steps,
                    use_advanced=use_advanced,
                    render=False,
                    progress_callback=progress_update_callback,
                    outer_rich_progress_active=True # Master mode has an active Rich progress
                )
                
                progress.update(task, completed=100, status="HoÃ n thÃ nh!")
                
            # Hiá»ƒn thá»‹ káº¿t quáº£
            if results:
                console.print("\n[bold underline bright_green]Tá»•ng káº¿t Pipeline Huáº¥n luyá»‡n:[/bold underline bright_green]")
                
                # Retrieve map_type_folder_name from results
                map_type_folder_name = results.get("map_type_folder_name", "N/A")

                if results.get("session_model_path") and results.get("session_model_performance"):
                    console.print(f"  {ICONS['model']} Model cá»§a phiÃªn nÃ y Ä‘Ã£ lÆ°u táº¡i: [cyan]{results['session_model_path']}[/cyan]")
                    session_perf = results['session_model_performance']
                    console.print(f"    Äiá»ƒm hiá»‡u nÄƒng (phiÃªn): [yellow]{session_perf.get('overall_score', 'N/A'):.4f}[/yellow]")
                    console.print(f"    Tá»· lá»‡ thÃ nh cÃ´ng TB (phiÃªn): {session_perf.get('avg_success_rate', 'N/A'):.2%}")

                if results.get("best_model_path") and results.get("best_model_performance"):
                    console.print(f"  {ICONS['success']} Model tá»‘t nháº¥t cho loáº¡i báº£n Ä‘á»“ '{map_type_folder_name}' Ä‘Ã£ cáº­p nháº­t/lÆ°u táº¡i: [bright_cyan]{results['best_model_path']}[/bright_cyan]")
                    best_perf = results['best_model_performance']
                    console.print(f"    Äiá»ƒm hiá»‡u nÄƒng (tá»‘t nháº¥t): [bold yellow]{best_perf.get('overall_score', 'N/A'):.4f}[/bold yellow]")
                    console.print(f"    Tá»· lá»‡ thÃ nh cÃ´ng TB (tá»‘t nháº¥t): {best_perf.get('avg_success_rate', 'N/A'):.2%}")

                    # Hiá»ƒn thá»‹ báº£ng chi tiáº¿t cho model tá»‘t nháº¥t
                    results_table = Table(show_header=True, box=box.ROUNDED, title_style="bold magenta", title=f"Chi tiáº¿t Model Tá»‘t Nháº¥t ({Path(results['best_model_path']).name})")
                    results_table.add_column("Chá»‰ sá»‘", style="cyan", overflow="fold")
                    results_table.add_column("GiÃ¡ trá»‹", style="green")
                
                    results_table.add_row("Äiá»ƒm tá»•ng há»£p", f"{best_perf.get('overall_score', 'N/A'):.4f}")
                    results_table.add_row("Tá»· lá»‡ thÃ nh cÃ´ng TB", f"{best_perf.get('avg_success_rate', 'N/A'):.2%}")
                    results_table.add_row("Pháº§n thÆ°á»Ÿng TB tá»•ng thá»ƒ", f"{best_perf.get('avg_reward_overall', 'N/A'):.2f}")
                    results_table.add_row("Äá»™ dÃ i Ä‘Æ°á»ng Ä‘i TB", f"{best_perf.get('avg_path_length_overall', 'N/A'):.2f}")
                    results_table.add_row("Tiá»n chi TB", f"{best_perf.get('avg_money_spent_overall', 'N/A'):.2f}")
                    results_table.add_row("NhiÃªn liá»‡u tiÃªu thá»¥ TB", f"{best_perf.get('avg_fuel_consumed_overall', 'N/A'):.2f}")
                    
                    console.print(results_table)

                    if best_perf.get('detailed_results_by_scenario'):
                        console.print("[bold magenta]  Chi tiáº¿t theo ká»‹ch báº£n Ä‘Ã¡nh giÃ¡ (model tá»‘t nháº¥t):[/bold magenta]")
                        for scenario_name, details in best_perf['detailed_results_by_scenario'].items():
                            short_name = shorten_text(scenario_name, 40)
                            console.print(f"    [italic cyan]{short_name}[/italic cyan]: SR={details.get('success_rate',0):.2f}, AvgRew={details.get('avg_reward',0):.2f}")
                else:
                    console.print("[yellow]KhÃ´ng cÃ³ thÃ´ng tin vá» model tá»‘t nháº¥t Ä‘Æ°á»£c tráº£ vá» tá»« pipeline.[/yellow]")
            else:
                console.print("[bold red]Pipeline huáº¥n luyá»‡n khÃ´ng tráº£ vá» káº¿t quáº£.[/bold red]")
            input("\nHuáº¥n luyá»‡n hoÃ n táº¥t! Nháº¥n Enter Ä‘á»ƒ tiáº¿p tá»¥c...")
    else:
        print("\nMASTER MODE - Tá»° Äá»˜NG Tá»I Æ¯U HÃ“A")
        print("Chá»‰ cáº§n nháº­p kÃ­ch thÆ°á»›c báº£n Ä‘á»“, má»i thá»© sáº½ Ä‘Æ°á»£c tá»± Ä‘á»™ng cáº¥u hÃ¬nh tá»‘i Æ°u!")
        
        print("\nCÃ¡c kÃ­ch thÆ°á»›c báº£n Ä‘á»“ há»— trá»£:")
        print("  [1] 8 x 8  - CÆ¡ báº£n      (~5-10 phÃºt)")
        print("  [2] 9 x 9  - Trung bÃ¬nh  (~10-15 phÃºt)")
        print("  [3] 10 x 10 - KhÃ³        (~15-25 phÃºt)")
        print("  [4] 12 x 12 - Ráº¥t khÃ³    (~30-40 phÃºt)")
        print("  [5] 15 x 15 - Cá»±c khÃ³    (~45-60 phÃºt)")
        print("  [0] Quay láº¡i")
        
        choice = input("\nChá»n kÃ­ch thÆ°á»›c báº£n Ä‘á»“ [1-5, 0 Ä‘á»ƒ quay láº¡i]: ")
        
        if choice == "0":
            return
            
        map_sizes = {
            "1": 8,
            "2": 9,
            "3": 10,
            "4": 12,
            "5": 15
        }
        
        if choice not in map_sizes:
            print("Lá»±a chá»n khÃ´ng há»£p lá»‡. Vui lÃ²ng chá»n láº¡i.")
            return
            
        map_size = map_sizes[choice]
        
        # Cáº¥u hÃ¬nh tá»‘i Æ°u tá»± Ä‘á»™ng
        if map_size <= 9:
            num_maps = 12
        elif map_size <= 10:
            num_maps = 10
        elif map_size <= 12:
            num_maps = 8
        else:
            num_maps = 5
            
        if map_size <= 8:
            training_steps = 125000  # Original: 50000
            use_advanced = False
        elif map_size <= 9:
            training_steps = 187500  # Original: 75000
            use_advanced = False
        elif map_size <= 10:
            training_steps = 250000  # Original: 100000
            use_advanced = True
        elif map_size <= 12:
            training_steps = 375000  # Original: 150000
            use_advanced = True
        else:
            training_steps = 500000  # Original: 200000
            use_advanced = True
            
        # Hiá»ƒn thá»‹ cáº¥u hÃ¬nh
        print(f"\nCáº¥u hÃ¬nh tá»‘i Æ°u cho báº£n Ä‘á»“ {map_size}x{map_size}:")
        print(f"  Sá»‘ lÆ°á»£ng báº£n Ä‘á»“: {num_maps}")
        print(f"  Sá»‘ bÆ°á»›c huáº¥n luyá»‡n: {training_steps:,}")
        print(f"  Sá»­ dá»¥ng ká»¹ thuáº­t nÃ¢ng cao: {'CÃ³' if use_advanced else 'KhÃ´ng'}")
        
        confirm = input("\nXÃ¡c nháº­n huáº¥n luyá»‡n vá»›i cáº¥u hÃ¬nh tá»‘i Æ°u? (y/n): ").lower() == 'y'
        
        if confirm:
            print(f"\nBáº¯t Ä‘áº§u huáº¥n luyá»‡n tá»‘i Æ°u cho báº£n Ä‘á»“ kÃ­ch thÆ°á»›c {map_size}x{map_size}...")
            
            # Cháº¡y pipeline huáº¥n luyá»‡n
            results = run_training_pipeline(
                map_size=map_size,
                num_maps=num_maps,
                training_steps=training_steps,
                use_advanced=use_advanced,
                render=False
            )
            
            # Hiá»ƒn thá»‹ káº¿t quáº£ cÆ¡ báº£n
            if results:
                console.print("\n[bold underline bright_green]Tá»•ng káº¿t Pipeline Huáº¥n luyá»‡n (CLI Mode):[/bold underline bright_green]")
                if results.get("session_model_path") and results.get("session_model_performance"):
                    console.print(f"  Model cá»§a phiÃªn nÃ y: {results['session_model_path']}")
                    session_perf = results['session_model_performance']
                    console.print(f"    Äiá»ƒm (phiÃªn): {session_perf.get('overall_score', 'N/A'):.4f}")
                if results.get("best_model_path") and results.get("best_model_performance"):
                    console.print(f"  Model tá»‘t nháº¥t cho loáº¡i báº£n Ä‘á»“: {results['best_model_path']}")
                    best_perf = results['best_model_performance']
                    console.print(f"    Äiá»ƒm (tá»‘t nháº¥t): {best_perf.get('overall_score', 'N/A'):.4f}")
            else:
                console.print("Pipeline huáº¥n luyá»‡n khÃ´ng tráº£ vá» káº¿t quáº£.")
            input("\nHuáº¥n luyá»‡n hoÃ n táº¥t! Nháº¥n Enter Ä‘á»ƒ tiáº¿p tá»¥c...")

def evaluate_model_ui():
    """
    Giao diá»‡n Ä‘Ã¡nh giÃ¡ model Ä‘Ã£ huáº¥n luyá»‡n
    """
    if RICH_AVAILABLE:
        console.print("\n[bold cyan]EVALUATE MODEL - ÄÃ¡nh giÃ¡ model Ä‘Ã£ huáº¥n luyá»‡n[/bold cyan]")
        
        # Lá»±a chá»n nguá»“n model
        source_choice_table = Table(box=box.SIMPLE, show_header=True)
        source_choice_table.add_column("Option", header_style="bold cyan", style=COLORS["menu_number"], justify="center")
        source_choice_table.add_column("Nguá»“n Model", header_style="bold cyan", style=COLORS["menu_text"])
        source_choice_table.add_row("1", "Model tá»‘t nháº¥t theo loáº¡i báº£n Ä‘á»“ (Best Models by Map Type)")
        source_choice_table.add_row("2", "Táº¥t cáº£ model theo phiÃªn (All Session Models)")
        source_choice_table.add_row("0", "Quay láº¡i Menu ChÃ­nh")

        source_panel = Panel(
            source_choice_table,
            title="[ CHá»ŒN NGUá»’N MODEL Äá»‚ ÄÃNH GIÃ ]",
            title_align="center",
            border_style=COLORS["border"],
            padding=(1,2)
        )
        console.print(source_panel)
        
        source_choice = Prompt.ask(
            "\n[bold cyan]Chá»n nguá»“n model[/bold cyan]",
            choices=["0", "1", "2"],
            default="1"
        )

        if source_choice == "0":
            return

        all_models = []
        search_path_description = ""

        if source_choice == "1":  # Model tá»‘t nháº¥t theo loáº¡i báº£n Ä‘á»“
            search_path_description = f"trong {BEST_ROBUST_MODELS_DIR}"
            if BEST_ROBUST_MODELS_DIR.exists():
                # QuÃ©t cÃ¡c thÆ° má»¥c con (loáº¡i báº£n Ä‘á»“), tÃ¬m file model .zip trong Ä‘Ã³
                for map_type_dir in BEST_ROBUST_MODELS_DIR.iterdir():
                    if map_type_dir.is_dir():
                        all_models.extend(list(map_type_dir.glob("*.zip")))
        elif source_choice == "2":  # Táº¥t cáº£ model theo phiÃªn
            search_path_description = f"trong {MODELS_DIR}"
            if MODELS_DIR.exists():
                # QuÃ©t MODELS_DIR vÃ  cÃ¡c thÆ° má»¥c con SESSION_ID
                all_models.extend(list(MODELS_DIR.rglob("*.zip")))
                # Loáº¡i trá»« cÃ¡c model trong BEST_ROBUST_MODELS_DIR náº¿u MODELS_DIR lÃ  cha cá»§a nÃ³
                if BEST_ROBUST_MODELS_DIR.is_relative_to(MODELS_DIR):
                    best_models_paths = {p for p in BEST_ROBUST_MODELS_DIR.rglob("*.zip")}
                    all_models = [m for m in all_models if m not in best_models_paths]

        if not all_models:
            console.print(f"[bold red]âŒ KhÃ´ng tÃ¬m tháº¥y model nÃ o {search_path_description}. Vui lÃ²ng huáº¥n luyá»‡n model trÆ°á»›c![/bold red]")
            input("\nNháº¥n Enter Ä‘á»ƒ trá»Ÿ vá» menu chÃ­nh...")
            return

        # PhÃ¢n loáº¡i model theo kÃ­ch thÆ°á»›c báº£n Ä‘á»“ (náº¿u cÃ³ thá»ƒ tá»« tÃªn file)
        models_by_display_group = {}  # Key sáº½ lÃ  string mÃ´ táº£ (vÃ­ dá»¥ "Size 8x8" hoáº·c tÃªn loáº¡i báº£n Ä‘á»“)
        
        for model_path in all_models:
            model_name = model_path.stem
            # Cá»‘ gáº¯ng trÃ­ch xuáº¥t kÃ­ch thÆ°á»›c tá»« tÃªn file hoáº·c thÆ° má»¥c cha
            size_match = None
            type_name_for_display = "Unknown Type / Session Model"

            # TrÆ°á»ng há»£p 1: Model tá»« BEST_ROBUST_MODELS_DIR
            if BEST_ROBUST_MODELS_DIR in model_path.parents:
                map_type_folder_name = model_path.parent.name
                type_name_for_display = f"Best: {map_type_folder_name}"
                # Cá»‘ gáº¯ng láº¥y size tá»« map_type_folder_name náº¿u cÃ³
                if "size_" in map_type_folder_name:
                    parts = map_type_folder_name.split('_')
                    for part in parts:
                        if 'x' in part and part.replace('x','').isdigit():
                            try:
                                size_val = int(part.split('x')[0])
                                if size_val in [8,9,10,12,15]:
                                    size_match = size_val
                                    break
                            except ValueError:
                                pass
                if size_match is None and "map_size_" in map_type_folder_name:
                    try:
                        size_val = int(map_type_folder_name.split("map_size_")[1].split("_")[0])
                        if size_val in [8,9,10,12,15]:
                            size_match = size_val
                    except ValueError:
                        pass

            # TrÆ°á»ng há»£p 2: Model tá»« thÆ° má»¥c session
            elif MODELS_DIR in model_path.parents and SESSION_ID_PATTERN_IN_FILENAME_RE.search(model_name):
                parent_dir_name = model_path.parent.name
                if parent_dir_name.startswith("map_size_"):
                    try:
                        size_val = int(parent_dir_name.split("_")[-1])
                        if size_val in [8,9,10,12,15]:
                            size_match = size_val
                    except ValueError:
                        pass
                if size_match is None:
                    for size_pattern in [f"size_{s}" for s in [8,9,10,12,15]]:
                        if size_pattern in model_name:
                            size_match = int(size_pattern.split('_')[1])
                            break

            group_key = f"Size {size_match}x{size_match}" if size_match else type_name_for_display
            
            if group_key not in models_by_display_group:
                models_by_display_group[group_key] = []
            models_by_display_group[group_key].append(model_path)

            # Láº¥y ngÃ y táº¡o file
            date_str = "N/A"
            try:
                timestamp = model_path.stat().st_mtime
                date_obj = datetime.fromtimestamp(timestamp)
                date_str = date_obj.strftime("%d/%m/%Y %H:%M")
            except Exception:  # nosemgrep
                pass  # Bá» qua náº¿u khÃ´ng láº¥y Ä‘Æ°á»£c ngÃ y táº¡o

        # Display models in groups
        group_options = sorted(models_by_display_group.keys())
        for group_name in group_options:
            console.print(f"\n[bold cyan]Group: {group_name}[/bold cyan]")
            model_table = Table(show_header=True, box=box.SIMPLE)
            model_table.add_column("ID", style="cyan", justify="center")
            model_table.add_column("Model Path", style="green")
            model_table.add_column("Created", style="yellow", justify="right")
            
            for idx, model_path in enumerate(models_by_display_group[group_name], 1):
                try:
                    model_name_for_display = str(model_path.relative_to(_ROOT_DIR))
                except ValueError:
                    model_name_for_display = str(model_path)
                
                date_str = "N/A"
                try:
                    timestamp = model_path.stat().st_mtime
                    date_str = datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M")
                except Exception:  # nosemgrep
                    pass
                
                model_table.add_row(str(idx), model_name_for_display, date_str)
            
            console.print(model_table)

def generate_training_map(map_size):
    """
    Táº¡o má»™t báº£n Ä‘á»“ huáº¥n luyá»‡n vá»›i kÃ­ch thÆ°á»›c vÃ  tá»· lá»‡ tá»‘i Æ°u.
    
    Args:
        map_size: KÃ­ch thÆ°á»›c báº£n Ä‘á»“
        
    Returns:
        Map: Äá»‘i tÆ°á»£ng báº£n Ä‘á»“ Ä‘Ã£ táº¡o
    """
    # Láº¥y tá»· lá»‡ tá»‘i Æ°u cho kÃ­ch thÆ°á»›c báº£n Ä‘á»“
    map_ratios = OPTIMAL_MAP_RATIOS.get(map_size, OPTIMAL_MAP_RATIOS[10])
    toll_ratio = map_ratios["toll_ratio"]
    gas_ratio = map_ratios["gas_ratio"]
    brick_ratio = map_ratios["brick_ratio"]
    
    # ThÃªm má»™t chÃºt biáº¿n thá»ƒ ngáº«u nhiÃªn Ä‘á»ƒ táº¡o sá»± Ä‘a dáº¡ng
    current_toll_ratio = toll_ratio * random.uniform(0.8, 1.2)
    current_gas_ratio = gas_ratio * random.uniform(0.8, 1.2)
    current_brick_ratio = brick_ratio * random.uniform(0.8, 1.2)
    
    # Táº¡o báº£n Ä‘á»“ má»›i
    return Map.generate_random(
        size=map_size,
        toll_ratio=current_toll_ratio,
        gas_ratio=current_gas_ratio,
        brick_ratio=current_brick_ratio
    )

DEFAULT_EVALUATION_SCENARIOS = [
    {
        "name": "Low Cost Focus",
        "max_fuel": 30.0, "initial_fuel": 25.0, "initial_money": 1500.0,
        "fuel_per_move": 0.3, "gas_station_cost": 15.0, "toll_base_cost": 200.0
    },
    {
        "name": "High Cost - Fuel Efficient",
        "max_fuel": 40.0, "initial_fuel": 35.0, "initial_money": 3000.0,
        "fuel_per_move": 0.2, "gas_station_cost": 50.0, "toll_base_cost": 150.0
    },
    {
        "name": "Low Fuel - Money Focus",
        "max_fuel": 20.0, "initial_fuel": 15.0, "initial_money": 4000.0,
        "fuel_per_move": 0.8, "gas_station_cost": 80.0, "toll_base_cost": 50.0
    },
    {
        "name": "Average Conditions", # Dá»±a trÃªn giÃ¡ trá»‹ giá»¯a cá»§a UI sliders
        "max_fuel": (DEFAULT_MAX_FUEL_RANGE[0] + DEFAULT_MAX_FUEL_RANGE[1]) / 2, 
        "initial_fuel": (DEFAULT_INITIAL_FUEL_RANGE[0] + DEFAULT_INITIAL_FUEL_RANGE[1]) / 2, # Sáº½ Ä‘Æ°á»£c clamp bá»Ÿi max_fuel
        "initial_money": (DEFAULT_INITIAL_MONEY_RANGE[0] + DEFAULT_INITIAL_MONEY_RANGE[1]) / 2,
        "fuel_per_move": (DEFAULT_FUEL_PER_MOVE_RANGE[0] + DEFAULT_FUEL_PER_MOVE_RANGE[1]) / 2,
        "gas_station_cost": (DEFAULT_GAS_STATION_COST_RANGE[0] + DEFAULT_GAS_STATION_COST_RANGE[1]) / 2,
        "toll_base_cost": (DEFAULT_TOLL_BASE_COST_RANGE[0] + DEFAULT_TOLL_BASE_COST_RANGE[1]) / 2
    }
]

def get_optimal_env_scenario(map_size):
    params = OPTIMAL_ENV_PARAMS.get(map_size, OPTIMAL_ENV_PARAMS[8])
    # OPTIMAL_ENV_PARAMS khÃ´ng cÃ³ max_fuel, nÃªn ta sáº½ láº¥y tá»« default range hoáº·c má»™t giÃ¡ trá»‹ há»£p lÃ½.
    # Trong trÆ°á»ng há»£p nÃ y, hÃ£y sá»­ dá»¥ng giÃ¡ trá»‹ initial_fuel lÃ m max_fuel cho ká»‹ch báº£n nÃ y náº¿u max_fuel khÃ´ng Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a cá»¥ thá»ƒ.
    max_fuel_val = params.get('max_fuel', params.get('initial_fuel',(DEFAULT_MAX_FUEL_RANGE[0] + DEFAULT_MAX_FUEL_RANGE[1]) / 2))

    return {
        "name": f"Optimal Env Params (Size {map_size})",
        "max_fuel": max_fuel_val, 
        "initial_fuel": params["initial_fuel"], # Sáº½ Ä‘Æ°á»£c clamp bá»Ÿi max_fuel á»Ÿ trÃªn trong env.reset
        "initial_money": params["initial_money"],
        "fuel_per_move": params["fuel_per_move"],
        "gas_station_cost": params["gas_station_cost"],
        "toll_base_cost": params["toll_base_cost"]
    }

def main():
    """HÃ m chÃ­nh Ä‘á»ƒ cháº¡y cÃ´ng cá»¥ tá»« command line"""
    parser = argparse.ArgumentParser(description="CÃ´ng cá»¥ tá»± Ä‘á»™ng huáº¥n luyá»‡n RL cho Ä‘á»‹nh tuyáº¿n xe táº£i")
    
    # Tham sá»‘
    parser.add_argument("--map-size", type=int, default=8, choices=[8, 9, 10, 12, 15],
                        help="KÃ­ch thÆ°á»›c báº£n Ä‘á»“ (8, 9, 10, 12, 15)")
    parser.add_argument("--num-maps", type=int, default=10,
                        help="Sá»‘ lÆ°á»£ng báº£n Ä‘á»“ táº¡o cho má»—i loáº¡i (train, eval, test)")
    parser.add_argument("--training-steps", type=int, default=50000,
                        help="Sá»‘ bÆ°á»›c huáº¥n luyá»‡n")
    parser.add_argument("--advanced", action="store_true",
                        help="Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nÃ¢ng cao (Double DQN, Dueling, PER)")
    parser.add_argument("--render", action="store_true",
                        help="Hiá»ƒn thá»‹ quÃ¡ trÃ¬nh huáº¥n luyá»‡n")
    parser.add_argument("--cli", action="store_true",
                        help="Cháº¡y á»Ÿ cháº¿ Ä‘á»™ command line, khÃ´ng hiá»ƒn thá»‹ UI")
    parser.add_argument("--master", action="store_true",
                        help="Cháº¡y á»Ÿ cháº¿ Ä‘á»™ master, chá»‰ cáº§n nháº­p kÃ­ch thÆ°á»›c báº£n Ä‘á»“")
    
    # Parse tham sá»‘
    args = parser.parse_args()
    
    # Náº¿u lÃ  cháº¿ Ä‘á»™ master qua command line
    if args.cli and args.master:
        map_size = args.map_size
        
        # Tá»± Ä‘á»™ng cáº¥u hÃ¬nh cÃ¡c tham sá»‘ tá»‘i Æ°u
        if map_size <= 9:
            num_maps = 12
        elif map_size <= 10:
            num_maps = 10
        elif map_size <= 12:
            num_maps = 8
        else:
            num_maps = 5
            
        if map_size <= 8:
            training_steps = 125000  # Original: 50000
            use_advanced = False
        elif map_size <= 9:
            training_steps = 187500  # Original: 75000
            use_advanced = False
        elif map_size <= 10:
            training_steps = 250000  # Original: 100000
            use_advanced = True
        elif map_size <= 12:
            training_steps = 375000  # Original: 150000
            use_advanced = True
        else:
            training_steps = 500000  # Original: 200000
            use_advanced = True
        
        # Hiá»ƒn thá»‹ thÃ´ng tin vÃ  cháº¡y
        print(f"\nCháº¿ Ä‘á»™ Master - KÃ­ch thÆ°á»›c báº£n Ä‘á»“: {map_size}x{map_size}")
        print(f"Sá»‘ lÆ°á»£ng báº£n Ä‘á»“: {num_maps}")
        print(f"Sá»‘ bÆ°á»›c huáº¥n luyá»‡n: {training_steps:,}")
        print(f"Sá»­ dá»¥ng ká»¹ thuáº­t nÃ¢ng cao: {'CÃ³' if use_advanced else 'KhÃ´ng'}")
        
        run_training_pipeline(
            map_size=map_size,
            num_maps=num_maps,
            training_steps=training_steps,
            use_advanced=use_advanced,
            render=args.render
        )
        return
    
    # Náº¿u lÃ  cháº¿ Ä‘á»™ command line thÃ´ng thÆ°á»ng
    elif args.cli:
        run_training_pipeline(
            map_size=args.map_size,
            num_maps=args.num_maps,
            training_steps=args.training_steps,
            use_advanced=args.advanced,
            render=args.render
        )
        return
    
    # Khá»Ÿi táº¡o thÆ° má»¥c
    setup_directories()
    
    # Khá»Ÿi táº¡o cáº¥u hÃ¬nh máº·c Ä‘á»‹nh
    map_size = args.map_size
    num_maps = args.num_maps
    training_steps = args.training_steps
    use_advanced = args.advanced
    
    # Hiá»ƒn thá»‹ giao diá»‡n chÃ­nh
    while True:
        clear_screen()
        display_header()
        display_menu()
        choice = get_user_choice()
        
        if choice == "0":
            # ThoÃ¡t
            if RICH_AVAILABLE:
                console.print("\n[bold green]Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng cÃ´ng cá»¥![/bold green]")
            else:
                print("\nCáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng cÃ´ng cá»¥!")
            break
            
        elif choice == "1":
            # Huáº¥n luyá»‡n nhanh
            if RICH_AVAILABLE:
                console.print("\n[bold cyan]QUICK TRAIN - Huáº¥n luyá»‡n nhanh vá»›i cáº¥u hÃ¬nh máº·c Ä‘á»‹nh (8x8)[/bold cyan]")
            else:
                print("\nQUICK TRAIN - Huáº¥n luyá»‡n nhanh vá»›i cáº¥u hÃ¬nh máº·c Ä‘á»‹nh (8x8)")
                
            display_training_config(8, 5, 30000, False)
            
            if RICH_AVAILABLE:
                confirm = Confirm.ask("Báº¡n cÃ³ muá»‘n tiáº¿p tá»¥c khÃ´ng?")
            else:
                confirm = input("Báº¡n cÃ³ muá»‘n tiáº¿p tá»¥c khÃ´ng? (y/n): ").lower() == 'y'
                
            if confirm:
                results = run_training_pipeline(
                    map_size=8,
                    num_maps=5,
                    training_steps=30000,
                    use_advanced=False,
                    render=False
                )
                
                if RICH_AVAILABLE:
                    if results:
                        console.print("\n[bold underline bright_green]Tá»•ng káº¿t Pipeline Huáº¥n luyá»‡n (Quick Train):[/bold underline bright_green]")
                        if results.get("best_model_path") and results.get("best_model_performance"):
                            console.print(f"  {ICONS['success']} Model tá»‘t nháº¥t Ä‘Ã£ lÆ°u/cáº­p nháº­t táº¡i: [bright_cyan]{results['best_model_path']}[/bright_cyan]")
                            best_perf = results['best_model_performance']
                            console.print(f"    Äiá»ƒm hiá»‡u nÄƒng: [bold yellow]{best_perf.get('overall_score', 'N/A'):.4f}[/bold yellow]")
                        else:
                            console.print("[yellow]KhÃ´ng cÃ³ thÃ´ng tin vá» model tá»‘t nháº¥t.[/yellow]")
                    else:
                        console.print("[red]Pipeline huáº¥n luyá»‡n khÃ´ng tráº£ vá» káº¿t quáº£.[/red]")
                    console.print("\n[bold green]Huáº¥n luyá»‡n hoÃ n táº¥t! Nháº¥n Enter Ä‘á»ƒ tiáº¿p tá»¥c...[/bold green]")
                else:
                    if results and results.get("best_model_path"):
                        print(f"Model tá»‘t nháº¥t Ä‘Ã£ lÆ°u/cáº­p nháº­t táº¡i: {results['best_model_path']}")
                    else:
                        print("KhÃ´ng cÃ³ thÃ´ng tin model tá»‘t nháº¥t hoáº·c pipeline lá»—i.")
                    input("\nHuáº¥n luyá»‡n hoÃ n táº¥t! Nháº¥n Enter Ä‘á»ƒ tiáº¿p tá»¥c...")
            
        elif choice == "2":
            # Master Mode - Chá»‰ cáº§n nháº­p kÃ­ch thÆ°á»›c báº£n Ä‘á»“
            master_mode()
            
        elif choice == "3":
            # Huáº¥n luyá»‡n nÃ¢ng cao
            if RICH_AVAILABLE:
                console.print("\n[bold cyan]ADVANCED TRAIN - Huáº¥n luyá»‡n nÃ¢ng cao (Double DQN, Dueling, PER)[/bold cyan]")
                
                map_size = int(Prompt.ask(
                    "Chá»n kÃ­ch thÆ°á»›c báº£n Ä‘á»“", 
                    choices=["8", "9", "10", "12", "15"],
                    default="10"
                ))
                
                num_maps = int(Prompt.ask(
                    "Sá»‘ lÆ°á»£ng báº£n Ä‘á»“ má»—i loáº¡i",
                    default="10"
                ))
                
                training_steps = int(Prompt.ask(
                    "Sá»‘ bÆ°á»›c huáº¥n luyá»‡n",
                    default="100000"
                ))
            else:
                print("\nADVANCED TRAIN - Huáº¥n luyá»‡n nÃ¢ng cao (Double DQN, Dueling, PER)")
                map_size = int(input("Chá»n kÃ­ch thÆ°á»›c báº£n Ä‘á»“ (8, 9, 10, 12, 15): ") or "10")
                num_maps = int(input("Sá»‘ lÆ°á»£ng báº£n Ä‘á»“ má»—i loáº¡i: ") or "10")
                training_steps = int(input("Sá»‘ bÆ°á»›c huáº¥n luyá»‡n: ") or "100000")
            
            display_training_config(map_size, num_maps, training_steps, True)
            
            if RICH_AVAILABLE:
                confirm = Confirm.ask("Báº¡n cÃ³ muá»‘n tiáº¿p tá»¥c khÃ´ng?")
            else:
                confirm = input("Báº¡n cÃ³ muá»‘n tiáº¿p tá»¥c khÃ´ng? (y/n): ").lower() == 'y'
                
            if confirm:
                results = run_training_pipeline(
                    map_size=map_size,
                    num_maps=num_maps,
                    training_steps=training_steps,
                    use_advanced=True,
                    render=False
                )
                
                if RICH_AVAILABLE:
                    if results:
                        console.print("\n[bold underline bright_green]Tá»•ng káº¿t Pipeline Huáº¥n luyá»‡n (Advanced Train):[/bold underline bright_green]")
                        if results.get("best_model_path") and results.get("best_model_performance"):
                            console.print(f"  {ICONS['success']} Model tá»‘t nháº¥t Ä‘Ã£ lÆ°u/cáº­p nháº­t táº¡i: [bright_cyan]{results['best_model_path']}[/bright_cyan]")
                            best_perf = results['best_model_performance']
                            console.print(f"    Äiá»ƒm hiá»‡u nÄƒng: [bold yellow]{best_perf.get('overall_score', 'N/A'):.4f}[/bold yellow]")
                        else:
                            console.print("[yellow]KhÃ´ng cÃ³ thÃ´ng tin vá» model tá»‘t nháº¥t.[/yellow]")
                    else:
                        console.print("[red]Pipeline huáº¥n luyá»‡n khÃ´ng tráº£ vá» káº¿t quáº£.[/red]")
                    console.print("\n[bold green]Huáº¥n luyá»‡n hoÃ n táº¥t! Nháº¥n Enter Ä‘á»ƒ tiáº¿p tá»¥c...[/bold green]")
                else:
                    if results and results.get("best_model_path"):
                        print(f"Model tá»‘t nháº¥t Ä‘Ã£ lÆ°u/cáº­p nháº­t táº¡i: {results['best_model_path']}")
                    else:
                        print("KhÃ´ng cÃ³ thÃ´ng tin model tá»‘t nháº¥t hoáº·c pipeline lá»—i.")
                    input("\nHuáº¥n luyá»‡n hoÃ n táº¥t! Nháº¥n Enter Ä‘á»ƒ tiáº¿p tá»¥c...")
            
        elif choice == "4":
            # ÄÃ¡nh giÃ¡ model - Use the new function
            evaluate_model_ui()
            
        elif choice == "5":
            # Táº¡o bá»™ báº£n Ä‘á»“ má»›i
            if RICH_AVAILABLE:
                console.print("\n[bold cyan]GENERATE MAPS - Táº¡o bá»™ báº£n Ä‘á»“ má»›i[/bold cyan]")
                
                map_size = int(Prompt.ask(
                    "Chá»n kÃ­ch thÆ°á»›c báº£n Ä‘á»“", 
                    choices=["8", "9", "10", "12", "15"],
                    default="8"
                ))
                
                num_maps = int(Prompt.ask(
                    "Sá»‘ lÆ°á»£ng báº£n Ä‘á»“ má»—i loáº¡i",
                    default="10"
                ))
            else:
                print("\nGENERATE MAPS - Táº¡o bá»™ báº£n Ä‘á»“ má»›i")
                map_size = int(input("Chá»n kÃ­ch thÆ°á»›c báº£n Ä‘á»“ (8, 9, 10, 12, 15): ") or "8")
                num_maps = int(input("Sá»‘ lÆ°á»£ng báº£n Ä‘á»“ má»—i loáº¡i: ") or "10")
            
            # Táº¡o báº£n Ä‘á»“
            generate_maps(map_size, num_maps, map_types=["train", "eval", "test"])
            
            if RICH_AVAILABLE:
                console.print("\n[bold green]Táº¡o báº£n Ä‘á»“ hoÃ n táº¥t! Nháº¥n Enter Ä‘á»ƒ tiáº¿p tá»¥c...[/bold green]")
            else:
                input("\nTáº¡o báº£n Ä‘á»“ hoÃ n táº¥t! Nháº¥n Enter Ä‘á»ƒ tiáº¿p tá»¥c...")
            
        elif choice == "6":
            # Hiá»ƒn thá»‹ thÃ´ng tin giÃºp Ä‘á»¡
            if RICH_AVAILABLE:
                help_text = """
                # HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG TRUCK RL AGENT MASTER

                ## QUICK TRAIN
                Sá»­ dá»¥ng cáº¥u hÃ¬nh máº·c Ä‘á»‹nh, kÃ­ch thÆ°á»›c báº£n Ä‘á»“ 8x8 vÃ  30,000 bÆ°á»›c huáº¥n luyá»‡n.
                PhÃ¹ há»£p Ä‘á»ƒ thá»­ nghiá»‡m nhanh trong vÃ²ng 5-10 phÃºt.
                
                ## MASTER MODE (KhuyÃªn dÃ¹ng)
                Cháº¿ Ä‘á»™ thÃ´ng minh - Báº¡n chá»‰ cáº§n nháº­p kÃ­ch thÆ°á»›c báº£n Ä‘á»“,
                cÃ´ng cá»¥ sáº½ tá»± Ä‘á»™ng cáº¥u hÃ¬nh táº¥t cáº£ cÃ¡c thÃ´ng sá»‘ cÃ²n láº¡i
                Ä‘á»ƒ Ä‘áº¡t hiá»‡u quáº£ tá»‘i Æ°u nháº¥t.
                
                ## ADVANCED TRAIN
                Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nÃ¢ng cao (Double DQN, Dueling Network, Prioritized Experience Replay)
                cho hiá»‡u suáº¥t tá»‘t hÆ¡n nhÆ°ng thá»i gian huáº¥n luyá»‡n lÃ¢u hÆ¡n.
                
                ## EVALUATE MODEL
                ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t cá»§a model Ä‘Ã£ huáº¥n luyá»‡n trÃªn cÃ¡c báº£n Ä‘á»“ test.
                
                ## GENERATE MAPS
                Táº¡o bá»™ báº£n Ä‘á»“ má»›i cho huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡.
                
                ## Giáº£i thÃ­ch cÃ¡c thÃ´ng sá»‘
                - **KÃ­ch thÆ°á»›c báº£n Ä‘á»“**: KÃ­ch thÆ°á»›c cá»§a báº£n Ä‘á»“, cÃ ng lá»›n cÃ ng phá»©c táº¡p
                - **Sá»‘ bÆ°á»›c huáº¥n luyá»‡n**: Sá»‘ bÆ°á»›c mÃ  agent sáº½ thá»±c hiá»‡n Ä‘á»ƒ há»c
                - **Ká»¹ thuáº­t nÃ¢ng cao**: Double DQN, Dueling Networks vÃ  Prioritized Experience Replay
                  giÃºp cáº£i thiá»‡n quÃ¡ trÃ¬nh há»c nhÆ°ng tá»‘n thá»i gian hÆ¡n
                """
                md = Markdown(help_text)
                help_panel = Panel(
                    md,
                    title="[ HELP MANUAL ]",
                    title_align="center",
                    border_style=COLORS["border"],
                    padding=(1, 2)
                )
                console.print(help_panel)
                input("\nNháº¥n Enter Ä‘á»ƒ tiáº¿p tá»¥c...")
            else:
                print("\nHÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG TRUCK RL AGENT MASTER:")
                print("\n1. QUICK TRAIN:")
                print("   Sá»­ dá»¥ng cáº¥u hÃ¬nh máº·c Ä‘á»‹nh, kÃ­ch thÆ°á»›c báº£n Ä‘á»“ 8x8 vÃ  30,000 bÆ°á»›c huáº¥n luyá»‡n.")
                print("\n2. MASTER MODE (KhuyÃªn dÃ¹ng):")
                print("   Cháº¿ Ä‘á»™ thÃ´ng minh - Báº¡n chá»‰ cáº§n nháº­p kÃ­ch thÆ°á»›c báº£n Ä‘á»“,")
                print("   cÃ´ng cá»¥ sáº½ tá»± Ä‘á»™ng cáº¥u hÃ¬nh táº¥t cáº£ cÃ¡c thÃ´ng sá»‘ cÃ²n láº¡i")
                print("   Ä‘á»ƒ Ä‘áº¡t hiá»‡u quáº£ tá»‘i Æ°u nháº¥t.")
                print("\n3. ADVANCED TRAIN:")
                print("   Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nÃ¢ng cao (Double DQN, Dueling Network, Prioritized Experience Replay)")
                print("   cho hiá»‡u suáº¥t tá»‘t hÆ¡n nhÆ°ng thá»i gian huáº¥n luyá»‡n lÃ¢u hÆ¡n.")
                print("\n4. EVALUATE MODEL:")
                print("   ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t cá»§a model Ä‘Ã£ huáº¥n luyá»‡n trÃªn cÃ¡c báº£n Ä‘á»“ test.")
                print("\n5. GENERATE MAPS:")
                print("   Táº¡o bá»™ báº£n Ä‘á»“ má»›i cho huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡.")
                input("\nNháº¥n Enter Ä‘á»ƒ tiáº¿p tá»¥c...")

if __name__ == "__main__":
    if RICH_AVAILABLE:
        try:
            main()
        except KeyboardInterrupt:
            console.print("\n[bold yellow]ÄÃ£ há»§y thao tÃ¡c. ThoÃ¡t chÆ°Æ¡ng trÃ¬nh.[/bold yellow]")
    else:
        try:
            main()
        except KeyboardInterrupt:
            print("\nÄÃ£ há»§y thao tÃ¡c. ThoÃ¡t chÆ°Æ¡ng trÃ¬nh.") 